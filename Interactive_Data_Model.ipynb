{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import param\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import traceback\n",
    "import panel as pn\n",
    "pn.extension(\"plotly\")\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "from bokeh.models.widgets.tables import NumberFormatter\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"class.py\").read())\n",
    "i_class = SpatialDataSet()\n",
    "\n",
    "i_file = pn.widgets.FileInput(name='Upload file')\n",
    "\n",
    "button_analysis = pn.widgets.Button(name='Analyse clusters', width=50)\n",
    "\n",
    "i_acquisition = pn.widgets.Select(options=[\"SILAC\", \"LFQ\"], name=\"Acquisition\", width=300)\n",
    "i_organism = pn.widgets.Select(options=[\"Human\", \"Mouse\",\"Arabidopsis\"], name=\"Organism\", width=300)\n",
    "\n",
    "i_clusterwidget = pn.widgets.Select(options=list(i_class.markerproteins), name=\"Cluster of interest\", width=300)\n",
    "i_mapwidget = pn.widgets.Select(options=[i_class.map_of_interest], name=\"Map of interest\", width=300)\n",
    "\n",
    "cache_uploaded = pn.widgets.Checkbox(value=False)\n",
    "cache_run = pn.widgets.Checkbox(value=False)\n",
    "\n",
    "analysis_status = pn.Pane(\"No analysis run yet\")\n",
    "filereading_status = \"No data import yet\"\n",
    "\n",
    "i_expname = pn.widgets.TextInput(name='Experiment Name', placeholder='Enter your experiment name here here...')\n",
    "#i_file = pn.widgets.Select(name='File',options=[\"6_deep_maps.txt\",\"LFQ_proteinGroups.txt\",\"proteinGroupsCOVID.txt\", \n",
    "#                                              \"proteinGroups_LFQ_Deep_3_Maps.txt\"])\n",
    "i_name_pattern = pn.widgets.Select(name='Name pattern',options=[\".* (?P<cond>.*)_(?P<rep>.*)_(?P<frac>.*)\",\".* (?P<rep>.*)_(?P<frac>.*)\",\n",
    "                                                                \".* (?P<cond>.*)_(?P<frac>.*)_(?P<rep>.*)\", \"Custom\"])\n",
    "i_custom_namepattern = pn.widgets.TextInput(name='Customized Name Pattern', placeholder='Enter a string here...e.g. \".* (?P<rep>.*)_(?P<frac>.*)\"')\n",
    "regex_pattern = {\n",
    "    \".* (?P<rep>.*)_(?P<frac>.*)\" : [\"MAP1_03K\",\"MAP3_03K\"],\n",
    "    \".* (?P<cond>.*)_(?P<rep>.*)_(?P<frac>.*)\" : [\"EGF_rep1_06K\",\"EGF_rep3_06K\"],\n",
    "    \".* (?P<cond>.*)_(?P<frac>.*)_(?P<rep>.*)\" : [\"Control_Mem_1\", \"Control_Cyt_1\"]\n",
    "    }\n",
    "pattern_examples = pn.widgets.Select(name = \"Examples\", options=regex_pattern[i_name_pattern.value])\n",
    "\n",
    "@pn.depends(i_name_pattern.param.value, i_custom_namepattern)\n",
    "def custimization(name_pattern, custom_namepattern):\n",
    "    if name_pattern == \"Custom\":\n",
    "        return i_custom_namepattern\n",
    "    else:\n",
    "        example_for_name_pattern = regex_pattern[name_pattern]\n",
    "        pattern_examples.options = example_for_name_pattern\n",
    "        return pattern_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class.name_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@pn.depends(i_file.param.value)\n",
    "def read_file(file):\n",
    "    if file is None:\n",
    "        filereading_status = \"No file is uploaded\"\n",
    "        cache_uploaded.value = False\n",
    "        return \"\"\n",
    "    else:\n",
    "        cache_uploaded.value = False\n",
    "        try:\n",
    "            i_class.df_original = pd.read_csv(BytesIO(file), sep=\"\\t\", comment=\"#\",\n",
    "                                           usecols=lambda x: bool(re.match(i_class.regex[\"imported_columns\"], x)),\n",
    "                                           low_memory=False)     \n",
    "            assert i_class.df_original.shape[0]>10 and i_class.df_original.shape[1]>5\n",
    "            filereading_status = i_class.df_original.head()\n",
    "            cache_uploaded.value = True\n",
    "            i_acquisition.disabled = False\n",
    "            #return pn.Column(pn.Pane(filereading_status, max_cols=10, width=20*filereading_status.shape[1]),\n",
    "             #                i_acquisition,i_organism, button_analysis)\n",
    "            return pn.Column(pn.Pane(filereading_status, max_cols=10, width=20*filereading_status.shape[1]),\n",
    "                   pn.Row(i_acquisition, i_expname), pn.Row(i_name_pattern, custimization), pn.Row(button_analysis))\n",
    "\n",
    "        except: \n",
    "            filereading_status = [traceback.format_exc(),file[0:50]]\n",
    "            cache_uploaded.value = False\n",
    "            return pn.Column(pn.Pane(filereading_status,width=200))     \n",
    "\n",
    "\n",
    "def update_object_selector(i_mapwidget):\n",
    "    i_mapwidget.options = list(i_class.map_names)\n",
    "    if i_class.map_of_interest not in list(i_class.map_names):\n",
    "            i_class.map_of_interest = i_class.map_names[0]\n",
    "\n",
    "number_of_analayses = 0           \n",
    "            \n",
    "def execution(event):\n",
    "    #prevent execution, if no data is uploaded yet\n",
    "    if cache_uploaded.value == False:\n",
    "        analysis_status.object = \"Please upload a file first\"\n",
    "    else:        \n",
    "       # number_of_analayses = number_of_analayses + 1\n",
    "       # if number_of_analayses.pop(0)\n",
    "        dashboard_analysis.objects = []\n",
    "        cache_run.value = False\n",
    "        i_acquisition.disabled = True\n",
    "        try:\n",
    "            #dashboard_analysis.pop(0)\n",
    "            dashboard_analysis.append(i_clusterwidget)\n",
    "            dashboard_analysis.append(i_mapwidget)\n",
    "            dashboard_analysis.append(analysis_tabs)\n",
    "            analysis_status.object = \"Analysis in progress\"\n",
    "            i_class.acquisition = i_acquisition.value\n",
    "            \n",
    "            i_class.acquisition = i_acquisition.value\n",
    "            if i_name_pattern.value == \"Custom\":\n",
    "                i_class.name_pattern = i_custom_namepattern.value\n",
    "            else:\n",
    "                i_class.name_pattern = i_name_pattern.value\n",
    "            \n",
    "            #if not i_name_pattern.value == \"Custom\":\n",
    "            #    i_class.name_pattern = i_name_pattern.value\n",
    "            #else:\n",
    "            #    i_class.name_pattern = i_custom_namepattern.value\n",
    "            i_class.expname = i_expname.value\n",
    "            i_class.processingdf()\n",
    "            update_object_selector(i_mapwidget)\n",
    "            i_class.perform_pca()\n",
    "            i_class.multiple_iterations()\n",
    "            i_class.distance_calculation()\n",
    "            analysis_status.object = \"Analysis finished! Please open the 'Analysis' tab!\"\n",
    "            cache_run.value = True\n",
    "    \n",
    "        except:\n",
    "            i_acquisition.disabled = False\n",
    "            \n",
    "            analysis_status.object = \"Analysis was not possible!\"\n",
    "            #analysis_status.object = [traceback.format_exc(), \"Analyis was not possible\"]\n",
    "            cache_run.value = False\n",
    "\n",
    "@pn.depends(i_clusterwidget.param.value,i_mapwidget.param.value, cache_run.param.value)\n",
    "def update_cluster_overview(clusterwidget, mapwidget, run):\n",
    "    try:\n",
    "        if run == True:\n",
    "            i_class.cluster_of_interest = clusterwidget\n",
    "            i_class.map_of_interest = mapwidget\n",
    "            list_genes = [goi for goi in i_class.genenames_sortedout_list if goi in i_class.markerproteins[clusterwidget]]\n",
    "            cluster_overview = pn.Column(\n",
    "                    pn.Row(pn.Pane(i_class.plot_pca(), width=500),\n",
    "                           pn.Pane(i_class.distance_boxplot(), width=500),\n",
    "                           pn.Pane(i_class.plottingdf(), width=500)),\n",
    "                    pn.Row(\n",
    "                        \"The following proteins were not consistently quantified throughout all maps: {}\".format(\n",
    "                            ', '.join(list_genes)) if len(list_genes) != 0 else\n",
    "                        \"All genes from this cluster are quantified in all maps.\")\n",
    "                    )\n",
    "            app_tabs.active = 1\n",
    "            return cluster_overview\n",
    "        else:\n",
    "            cluster_overview = \"Run analysis first!\"\n",
    "            return cluster_overview\n",
    "    except:\n",
    "        update_status = [traceback.format_exc(), \"Analyis was not possible\"]\n",
    "        return update_status\n",
    "\n",
    "    \n",
    "@pn.depends(i_clusterwidget.param.value, cache_run.param.value)\n",
    "def update_cluster_details(clusterwidget, run):\n",
    "    try:\n",
    "        if run == True:\n",
    "            i_class.cluster_of_interest = clusterwidget\n",
    "            cluster_details = i_class.distance_to_median_boxplot()\n",
    "            return cluster_details\n",
    "        else:\n",
    "            cluster_details = \"Run analysis first!\"\n",
    "            return cluster_details\n",
    "    except:\n",
    "        update_status = [traceback.format_exc(), \"Analyis was not possible\"]\n",
    "        return update_status\n",
    "\n",
    "\n",
    "@pn.depends(cache_run.param.value)\n",
    "def show_tabular_overview(run):\n",
    "    try:\n",
    "        if run == True:\n",
    "            content = pn.Column(\n",
    "                pn.panel(i_class.results_overview_table(),width=500),\n",
    "                pn.widgets.FileDownload(\n",
    "                    callback=table_download, filename='cluster_distances.csv')\n",
    "            )\n",
    "            return content\n",
    "        else:\n",
    "            content = \"Please, upload a file first and press ‘Analyse clusters’\"\n",
    "            return content\n",
    "    except:\n",
    "        content = [traceback.format_exc(), \"Analyis was not possible\"]\n",
    "        return content\n",
    "\n",
    "@pn.depends(cache_run.param.value)\n",
    "def table_download(run):\n",
    "    df = i_class.results_overview_table()\n",
    "    sio = StringIO()\n",
    "    df.to_csv(sio)\n",
    "    sio.seek(0)\n",
    "    return sio \n",
    "\n",
    "button_analysis.on_click(execution)  \n",
    "\n",
    "dasboard_home = pn.Column(i_file, read_file,analysis_status, name=\"Home\", css_classes=[\"content-width\"])\n",
    "dashboard_analysis = pn.Column(\"Please, upload a file first and press 'Analyse clusters'\", name=\"Analysis\", css_classes=[\"content-width\"])\n",
    "\n",
    "analysis_tabs = pn.Tabs(margin=10, css_classes=[\"content-width\"], dynamic=True)\n",
    "analysis_tabs.append((\"Cluster Overview\", update_cluster_overview))\n",
    "analysis_tabs.append((\"Cluster Details\", update_cluster_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_tabs = pn.Tabs(margin=10, css_classes=[\"content-width\"], dynamic=True)\n",
    "app_tabs.append((\"Home\", dasboard_home))\n",
    "app_tabs.append((\"Analysis\", dashboard_analysis))\n",
    "app_tabs.append((\"Download\", show_tabular_overview))\n",
    "app_tabs.append((\"About\", \"Explanation of what's going on here\"))\n",
    "\n",
    "\n",
    "#i_search = pn.widgets.TextInput(name=\"Search\")\n",
    "app_center = pn.Column(pn.Row(pn.Pane(\"# QC tool for Spatial Proteomics\"),\n",
    "                              pn.layout.HSpacer(),\n",
    "                              #i_search,\n",
    "                              #width=1600, \n",
    "                              margin=10),\n",
    "                       app_tabs,\n",
    "                       pn.Spacer(background=\"#DDDDDD\", height=100, margin=0))\n",
    "app = pn.GridSpec(sizing_mode=\"stretch_both\", margin=0)\n",
    "app[0,0] = pn.Spacer(background=\"#DDDDDD\", margin=0)\n",
    "app[0,9] = pn.Spacer(background=\"#DDDDDD\", margin=0)\n",
    "app[0,1:8] = app_center\n",
    "\n",
    "pwd = pn.widgets.PasswordInput(name=\"Please enter password for access.\")\n",
    "app_container = pn.Column(pwd)\n",
    "\n",
    "def check_pwd(event, app=app):\n",
    "    pwd = event.new\n",
    "    if pwd == \"pwd\":\n",
    "        app_container[0]=app\n",
    "pwd.param.watch(check_pwd, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " try:\n",
    "     server.stop()\n",
    " except:\n",
    "     print(\"First server startup\")\n",
    " server = app.show(port=5063, websocket_max_message_size=1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class.analysed_datasets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class.analysed_datasets_dict['l']['changes in Shape after filtering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class.analysed_datasets_dict['s']['changes in Shape after filtering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class.analysed_datasets_dict['cov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_file = 'LFQ_proteinGroups.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_name_pattern.value = '.* (?P<rep>.*_.*)_(?P<frac>.*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_name_pattern.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['LFQ_proteinGroups.txt', 'LFQ', '.* (?P<rep>.*_.*)_(?P<frac>.*)', 'LFQ_1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
