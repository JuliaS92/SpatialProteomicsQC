{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import param\n",
    "import re\n",
    "import traceback\n",
    "import panel as pn\n",
    "pn.extension(\"plotly\")\n",
    "import io\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "from bokeh.models.widgets.tables import NumberFormatter\n",
    "import plotly.express as px\n",
    "import json\n",
    "import os\n",
    "from importlib import reload\n",
    "import pkg_resources\n",
    "import time\n",
    "\n",
    "try:\n",
    "    type(domaps)\n",
    "    print(\"reloading library\")\n",
    "    domaps = reload(domaps)\n",
    "except Exception as ex:\n",
    "    print(\"loading library first time\")\n",
    "    import domaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## panel and plotly settings and customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    ".detail_menu .bk-headers-wrapper{\n",
    "  border-bottom: 2px solid #0a5da8 !important;\n",
    "  margin-bottom: 10px;\n",
    "  min-width: 1000px;\n",
    "}\n",
    ".detail_menu .bk-tab{\n",
    "  color: #0a5da8;\n",
    "}\n",
    ".detail_menu .bk-active{\n",
    "  border-color: #0a5da8 !important;\n",
    "  border-width: 2px 1px 0px 1px !important;\n",
    "  color: #111111 !important;\n",
    "}\n",
    "\n",
    ".main_menu .bk-headers-wrapper{\n",
    "  border-bottom: 2px solid #0a5da8 !important;\n",
    "  margin-bottom: 10px;\n",
    "  min-width: 1000px;\n",
    "}\n",
    ".main_menu .bk-tab{\n",
    "  color: #0a5da8;\n",
    "  font-size: 120%;\n",
    "  font-weight: bold;\n",
    "}\n",
    ".main_menu .bk-active{\n",
    "  border-color: #0a5da8 !important;\n",
    "  border-width: 2px 1px 0px 1px !important;\n",
    "  color: #111111 !important;\n",
    "}\n",
    ".content-width{\n",
    "  min-width: 1000px;\n",
    "}\n",
    "\n",
    ".bk-tabs-header{\n",
    "  min-width: 1000px;\n",
    "}\n",
    "\n",
    ".card-title:first-child{\n",
    "  font-size: 13px;\n",
    "}\n",
    "\n",
    ".button-main .bk-btn{\n",
    "  font-size: 120%;\n",
    "  font-weight: bold;\n",
    "}\n",
    "\"\"\"\n",
    "pn.extension(raw_css=[css])\n",
    "\n",
    "plotly_config={\n",
    "      'toImageButtonOptions': {\n",
    "            'format': 'svg', # one of png, svg, jpeg, webp\n",
    "            'filename': 'figure'\n",
    "      }\n",
    "}\n",
    "\n",
    "def resize(el):\n",
    "    try:\n",
    "        el.append(None)\n",
    "        el.pop(-1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data that will be stored in memory during each session\n",
    "## dataset analysed and displayed in the single analysis tab\n",
    "mem_single_analysis = None\n",
    "i_class = None\n",
    "## dataset collection analysed and displayed in the benchmarking tab\n",
    "mem_benchmark = None\n",
    "i_class_comp = None\n",
    "## currently available datasets to select for benchmarking\n",
    "mem_available_datasets = dict()\n",
    "\n",
    "with open(\"textfragments.json\", \"r\") as file:\n",
    "    textfragments = json.load(file)\n",
    "\n",
    "DEBUG = True\n",
    "MAX_SIZE_MB = 80\n",
    "CONTENT_WIDTH = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Served panel object:\n",
    "app = pn.GridSpec()#sizing_mode=\"stretch_both\", margin=0)\n",
    "app[0,0] = pn.Spacer(background=\"white\", margin=0) #\"#DDDDDD\"\n",
    "app[0,9] = pn.Spacer(background=\"white\", margin=0) #\"#DDDDDD\"\n",
    "\n",
    "#### Insert main content container\n",
    "app_center = pn.Column(pn.Row(pn.Pane(\"# QC tool for Spatial Proteomics\", width = 600),\n",
    "                              pn.layout.HSpacer(),\n",
    "                              margin=10),\n",
    "                       pn.Row(name=\"main_content\"),\n",
    "                       pn.Spacer(background=\"#DDDDDD\", height=100, margin=0)\n",
    "                      )\n",
    "app[0,1:8] = app_center\n",
    "\n",
    "#### Insert main menu tab object\n",
    "app_tabs = pn.Tabs(margin=10, css_classes=[\"content-width\", \"main_menu\"], dynamic=True)\n",
    "app_center.objects[[i.name for i in app_center].index(\"main_content\")] = app_tabs\n",
    "\n",
    "#### Append individual dashboards\n",
    "## Home\n",
    "dashboard_home = pn.Column(\n",
    "    \"Interface loading ...\",\n",
    "    name=\"home\", css_classes=[\"content-width\"])\n",
    "app_tabs.append((\"Home\", dashboard_home))\n",
    "\n",
    "## Single analysis\n",
    "dashboard_analysis = pn.Column(\n",
    "    \"Interface loading ...\",\n",
    "    name=\"analysis\", css_classes=[\"content-width\"])\n",
    "app_tabs.append((\"Analysis\", dashboard_analysis))\n",
    "analysis_tabs = pn.Tabs(margin=10, css_classes=[\"content-width\", \"detail_menu\"], dynamic=True)\n",
    "\n",
    "## Benchmark\n",
    "dashboard_benchmark = pn.Column(\n",
    "    \"Interface loading ...\",\n",
    "    name=\"benchmark\", css_classes=[\"content-width\"])\n",
    "app_tabs.append((\"Benchmark\", dashboard_benchmark))\n",
    "comparison_tabs = pn.Tabs(margin=10, css_classes=[\"content-width\", \"detail_menu\"], dynamic=True, width=1000)\n",
    "\n",
    "## Manage datasets\n",
    "#dashboard_MissclassificationMatrix = pn.Column(\n",
    "#    \"Please, upload a file first and press 'Analyse clusters'\",\n",
    "#    name=\"SVM Analysis\", css_classes=[\"content-width\"])\n",
    "#dashboard_amendment = pn.Column(\n",
    "#    \"Please, upload a json file first\",\n",
    "#    name=\"Renaming\", css_classes=[\"content-width\"])\n",
    "dashboard_manageDatasets = pn.Column(\n",
    "    \"Interface loading ...\",\n",
    "    name=\"Manage datasets\", css_classes=[\"content-width\"])\n",
    "app_tabs.append((\"Manage Datasets\", dashboard_manageDatasets))\n",
    "\n",
    "#amendment_tabs = pn.Tabs(margin=10, css_classes=[\"content-width\", \"detail_menu\"], dynamic=True)\n",
    "#amendment_tabs.append((\"Change Experiment name and comment\", dashboard_amendment))\n",
    "#amendment_tabs.append((\"SVM Upload\", dashboard_MissclassificationMatrix))\n",
    "\n",
    "## About\n",
    "app_tabs.append((\"About\", pn.Row(pn.Pane(textfragments[\"about_intro\"], width=1000))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App serving\n",
    "Switch cells below between markup and code to set up for server hosting from the command line (app.servable) vs. local hosting from python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    server.stop()\n",
    "except Exception:\n",
    "    print(\"First server startup\")\n",
    "server = app.show(port=5067, websocket_max_message_size=MAX_SIZE_MB*1024*1024,\n",
    "                  http_server_kwargs={'max_buffer_size': MAX_SIZE_MB*1024*1024})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "app.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell structuring\n",
    "All cells below contain one or several sets of these points:\n",
    "- (Dashboard structure)\n",
    "- Layout and widget elements (outside in)\n",
    "- Layout assembly and appending\n",
    "- Callback definitions\n",
    "- Positioning of callback outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dashboard structure\n",
    "########################\n",
    "\n",
    "#### Layout elements\n",
    "####################\n",
    "\n",
    "#### Append layout to dashboard\n",
    "###############################\n",
    "\n",
    "#### Callbacks\n",
    "##############\n",
    "# list\n",
    "# of\n",
    "# callbacks\n",
    "\n",
    "#### Callback output positioning\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dashboard structure\n",
    "########################\n",
    "# already defined as single column\n",
    "dashboard_home.objects = []\n",
    "\n",
    "#### Layout elements\n",
    "####################\n",
    "lo_home_intro = pn.Pane(textfragments[\"home_intro\"], width=CONTENT_WIDTH)\n",
    "btn_home_analysesingle = pn.widgets.Button(name=\"Format and analyse single experiment\",\n",
    "                                           button_type=\"success\", width=400, height=50,\n",
    "                                           css_classes=[\"button-main\"])\n",
    "lo_home_singleinstructions = pn.Column(\n",
    "    pn.Pane(textfragments[\"home_single_shortinstructions\"], width=CONTENT_WIDTH),\n",
    "    pn.Card(\"Add screenshot tutorial here.\", header=\"Tutorial\", width=CONTENT_WIDTH,\n",
    "            name=\"tutorial_single\", collapsed=True)\n",
    ")\n",
    "btn_home_benchmark = pn.widgets.Button(name=\"Benchmark multiple experiments\",\n",
    "                                       button_type=\"success\", width=400, height=50,\n",
    "                                       css_classes=[\"button-main\"])\n",
    "lo_home_benchmarkinstructions = pn.Column(\n",
    "    pn.Pane(textfragments[\"home_benchmark_shortinstructions\"], width=CONTENT_WIDTH),\n",
    "    pn.Card(\"Add screenshot tutorial here.\", header=\"Tutorial\", width=CONTENT_WIDTH,\n",
    "            name=\"tutorial_benchmark\", collapsed=True)\n",
    ")\n",
    "\n",
    "#### Append layout to dashboard\n",
    "###############################\n",
    "for el in [lo_home_intro,\n",
    "           btn_home_analysesingle, lo_home_singleinstructions,\n",
    "           btn_home_benchmark, lo_home_benchmarkinstructions]:\n",
    "    dashboard_home.append(el)\n",
    "\n",
    "#### Callbacks\n",
    "##############\n",
    "# home_gotosingleanalysis\n",
    "# home_gotobenchmark\n",
    "\n",
    "def home_gotosingleanalysis(event):\n",
    "    app_tabs.active = [el.name for el in app_tabs].index(\"analysis\")\n",
    "btn_home_analysesingle.on_click(home_gotosingleanalysis)\n",
    "\n",
    "def home_gotobenchmark(event):\n",
    "    app_tabs.active = [el.name for el in app_tabs].index(\"benchmark\")\n",
    "btn_home_benchmark.on_click(home_gotobenchmark)\n",
    "\n",
    "#### Callback output positioning\n",
    "################################\n",
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis tab\n",
    "- File config\n",
    "- Analysis output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dashboard structure\n",
    "########################\n",
    "dashboard_analysis.objects = [\n",
    "    pn.Column(name=\"file_config\"),\n",
    "    pn.Column(name=\"analysis_output\")\n",
    "]\n",
    "\n",
    "#### Layout elements\n",
    "#### File config\n",
    "####################\n",
    "lo_read_file = pn.Card(header=\"### Upload configuration\", min_width=400)\n",
    "lo_config_instructions = pn.Card(\n",
    "    pn.Pane(textfragments[\"upload_details\"]), header=\"### Details on configuring your data\", width=400)\n",
    "\n",
    "i_file = pn.widgets.FileInput(name=\"Upload file\")\n",
    "loading_status = pn.Row()\n",
    "idle = pn.indicators.LoadingSpinner(value=False, width=100, height=100, color=\"primary\")\n",
    "loading = pn.indicators.LoadingSpinner(value=True, width=100, height=100, color=\"primary\")\n",
    "i_acquisition = pn.widgets.Select(options=[\"LFQ6 - MQ\", \"LFQ5 - MQ\", \"LFQ6 - Spectronaut\", \"LFQ5 - Spectronaut\",\n",
    "                                           \"SILAC - MQ\", \"Custom\"], name=\"Acquisition\", width=300)\n",
    "i_organism = pn.widgets.Select(options=[el.split(\".csv\")[0] for el in\n",
    "                                        pkg_resources.resource_listdir(\"domaps\", \"annotations/complexes\")],\n",
    "                               name=\"Organism\", width=300, value=\"Homo sapiens - Uniprot\")\n",
    "i_comment = pn.widgets.input.TextAreaInput(\n",
    "    name=\"Additional Comments\",\n",
    "    placeholder=\"Write any kind of information associated with this dataset here...\")\n",
    "analysis_status = pn.Pane(\"\", width=300)\n",
    "filereading_status = pn.Pane(\"No data import yet\", width=300)\n",
    "i_expname = pn.widgets.TextInput(name=\"Experiment Name\", placeholder=\"Enter your experiment name here here...\")\n",
    "i_custom_namepattern = pn.widgets.TextInput(name=\"Customized Name Pattern\",\n",
    "                                            placeholder=\"Enter a string here...e.g.: .* (?P<rep>.*)_(?P<frac>.*)\")\n",
    "regex_pattern = {\n",
    "    \"(?P<rep>.*)_(?P<frac>.*)\" : [\"Spectronaut MAP1_03K\"],\n",
    "    \".* (?P<rep>.*)_(?P<frac>.*)\" : [\"MAP1_03K\",\"MAP3_03K\"],\n",
    "    \".* (?P<cond>.*)_(?P<rep>.*)_(?P<frac>.*)\" : [\"EGF_rep1_06K\",\"EGF_rep3_06K\"],\n",
    "    \".* (?P<cond>.*)_(?P<frac>.*)_(?P<rep>.*)\" : [\"Control_Mem_1\", \"Control_Cyt_1\"],\n",
    "    \".* (?P<cond>.*)_(?P<frac>.*_.*)_(?P<rep>.*)\" : [\"4h_mem_frac3_1\", \"co_mem_frac2_2\"]\n",
    "    }\n",
    "i_name_pattern = pn.widgets.Select(name=\"Name pattern\",\n",
    "                                   options=[\".* (?P<rep>.*)_(?P<frac>.*)\", \".* (?P<frac>.*)_(?P<rep>.*)\",\n",
    "                                            \".* (?P<cond>.*)_(?P<rep>.*)_(?P<frac>.*)\",\n",
    "                                            \".* (?P<cond>.*)_(?P<frac>.*)_(?P<rep>.*)\",\n",
    "                                            \".* (?P<cond>.*)_(?P<frac>.*_.*)_(?P<rep>.*)\",\n",
    "                                            \"(?P<rep>.*)_(?P<frac>.*)\", \"Custom\"])\n",
    "i_pattern_examples = pn.widgets.Select(name = \"Examples\", options=regex_pattern[i_name_pattern.value])\n",
    "\n",
    "button_analysis = pn.widgets.Button(name=\"Analyse dataset\", width=50)\n",
    "\n",
    "# gene reannotation\n",
    "i_reannotate_genes = pn.widgets.Select(\n",
    "    options=[\"don't reannotate\", \"from uniprot fasta headers\", \"from uniprot.org\", \"from uniprot tab download\"],\n",
    "    name=\"Reannotate genes\", value=\"from uniprot fasta headers\")\n",
    "i_reannotate_genes_source = pn.widgets.Select(options=[\"upload custom file\"], value=\"select last\",\n",
    "                                              name=\"Annotation source:\")\n",
    "i_reannotate_genes_file = pn.widgets.FileInput(name=\"Upload gene annotation file\")\n",
    "\n",
    "# custom acqusition\n",
    "i_custom_cids = pn.widgets.Select(name=\"column containing protein ids\")\n",
    "i_custom_cgenes = pn.widgets.Select(name=\"column containing gene names\")\n",
    "i_custom_cdata = pn.widgets.MultiSelect(name=\"columns containing data\")\n",
    "i_custom_normalized = pn.widgets.Checkbox(name=\"profiles are already 0-1 normalized (profile sum = 1)\")\n",
    "\n",
    "# LFQ acquisition\n",
    "i_consecutiveLFQi = pn.widgets.IntSlider(name=\"Consecutive LFQ intensities\", start=1, end=10, step=1, value=4)\n",
    "i_summed_MSMS_counts = pn.widgets.IntSlider(name=\"Summed MS/MS counts ≥ 2n x number of fractions\",\n",
    "                                            start=0, end=10, step=1, value=2)\n",
    "\n",
    "# SILAC acquisition\n",
    "i_RatioHLcount = pn.widgets.IntSlider(name=\"Quantification events (Ratio H/L Count)\", start=1, end=10, step=1, value=2)\n",
    "i_RatioVariability = pn.widgets.IntSlider(name=\"Ratio H/L variability [%]\", start=0, end=100, step=5, value=30)\n",
    "#### Append layout to dashboard\n",
    "#### File config\n",
    "###############################\n",
    "dashboard_analysis.objects[[el.name for el in dashboard_analysis].index(\"file_config\")].objects = []\n",
    "for el in [i_file,\n",
    "    pn.Row(\n",
    "        pn.Column(lo_read_file, analysis_status, loading_status),\n",
    "        lo_config_instructions\n",
    "    )\n",
    "]:\n",
    "    dashboard_analysis.objects[[el.name for el in dashboard_analysis].index(\"file_config\")].append(el)\n",
    "\n",
    "#### Callbacks\n",
    "#### File config\n",
    "################\n",
    "# response_pattern\n",
    "# response_acquisition\n",
    "# response_reannotation\n",
    "# read_file\n",
    "# execution\n",
    "\n",
    "cache_uploaded = pn.widgets.Checkbox(value=False)\n",
    "cache_run = pn.widgets.Checkbox(value=False)\n",
    "#define widgets that should be disbled after run==True\n",
    "wdgts = [i_acquisition,i_name_pattern,i_expname, i_pattern_examples, button_analysis, i_expname, i_organism,\n",
    "         i_consecutiveLFQi, i_summed_MSMS_counts, i_RatioHLcount, i_RatioVariability, i_comment,\n",
    "         i_custom_cids, i_custom_cgenes, i_custom_cdata, i_custom_normalized,\n",
    "         i_reannotate_genes, i_reannotate_genes_file, i_reannotate_genes_source]\n",
    "\n",
    "\n",
    "@pn.depends(i_file.param.value)\n",
    "def read_file(file):\n",
    "    if file is None:\n",
    "        filereading_status = \"No file is uploaded\"\n",
    "        cache_uploaded.value = False\n",
    "        return filereading_status\n",
    "    else:\n",
    "        cache_uploaded.value = False\n",
    "        try:\n",
    "            if i_file.filename[-3:] == \"xls\" or i_file.filename[-3:] == \"txt\":\n",
    "                df_original = pd.read_csv(BytesIO(file), sep=\"\\t\", comment=\"#\", nrows=5, usecols=lambda x: bool(re.match(domaps.SpatialDataSet.regex[\"imported_columns\"], x)), low_memory=True)\n",
    "                if len(df_original.columns) < 5:\n",
    "                    df_original = pd.read_csv(BytesIO(file), sep=\"\\t\", comment=\"#\", nrows=5)\n",
    "            elif i_file.filename[-3:] == \"csv\":\n",
    "                df_original = pd.read_csv(BytesIO(file), sep=\",\", comment=\"#\", nrows=5, usecols=lambda x: bool(re.match(domaps.SpatialDataSet.regex[\"imported_columns\"], x)), low_memory=True)\n",
    "                if len(df_original.columns) < 5:\n",
    "                    df_original = pd.read_csv(BytesIO(file), sep=\",\", comment=\"#\", nrows=5)\n",
    "            else:\n",
    "                return pn.Column(\"Upload either csv, xls, or txt formatted files.\")\n",
    "            cache_uploaded.value = True\n",
    "            analysis_status.object = \"No analysis run yet\"\n",
    "            for wdgt in wdgts:\n",
    "                wdgt.disabled = False\n",
    "\n",
    "            return pn.Column(pn.Row(pn.widgets.DataFrame(df_original, height=200, width=600, disabled=True)),#i_class.\n",
    "                             pn.Row(i_expname), \n",
    "                             pn.Row(i_organism, i_acquisition),\n",
    "                             pn.Row(i_name_pattern, response_pattern),\n",
    "                             pn.Row(i_reannotate_genes, response_reannotation),\n",
    "                             pn.Row(response_acquisition), \n",
    "                             pn.Row(i_comment),\n",
    "                             pn.Row(button_analysis))\n",
    "\n",
    "        except Exception: \n",
    "            filereading_status = traceback.format_exc()\n",
    "            cache_uploaded.value = False\n",
    "            return filereading_status\n",
    "\n",
    "@pn.depends(i_name_pattern.param.value)\n",
    "def response_pattern(name_pattern):\n",
    "    if name_pattern == \"Custom\":\n",
    "        return i_custom_namepattern\n",
    "    else:\n",
    "        example_for_name_pattern = regex_pattern[name_pattern]\n",
    "        i_pattern_examples.options = example_for_name_pattern\n",
    "        return i_pattern_examples\n",
    "\n",
    "\n",
    "@pn.depends(i_acquisition.param.value)\n",
    "def response_acquisition(acquisition):\n",
    "    if acquisition == \"SILAC - MQ\":\n",
    "        return pn.Column(pn.Row(pn.Pane(\"Stringency filtering\")), pn.Row(i_RatioHLcount, i_RatioVariability))\n",
    "    elif acquisition == \"Custom\":\n",
    "        try:\n",
    "            if i_file.filename[-3:] == \"xls\" or i_file.filename[-3:] == \"txt\":\n",
    "                columns = list(pd.read_csv(BytesIO(i_file.value), sep=\"\\t\", comment=\"#\", nrows=2).columns)\n",
    "            elif i_file.filename[-3:] == \"csv\":\n",
    "                columns = list(pd.read_csv(BytesIO(i_file.value), sep=\",\", comment=\"#\", nrows=2).columns)\n",
    "            else:\n",
    "                return \"Failed to read file\"\n",
    "            i_custom_cids.options = columns\n",
    "            i_custom_cgenes.options = columns\n",
    "            i_custom_cdata.options = columns\n",
    "            return pn.Column(\"Please note that the custom upload is still under development and currently assumes 0-1 normalized data.\",\n",
    "                             pn.Row(pn.Column(i_custom_cids, i_custom_cgenes), i_custom_cdata),\n",
    "                             #i_custom_normalized\n",
    "                            )\n",
    "        except Exception:\n",
    "            return traceback.format_exc()\n",
    "    else:\n",
    "        return pn.Column(pn.Row(pn.Pane(\"Stringency filtering\")), pn.Row(i_consecutiveLFQi, i_summed_MSMS_counts))\n",
    "\n",
    "@pn.depends(i_reannotate_genes.param.value, i_reannotate_genes_source.param.value)\n",
    "def response_reannotation(mode, source):\n",
    "    if mode in [\"don't reannotate\", \"from uniprot.org\"]:\n",
    "        i_reannotate_genes_source.options = i_reannotate_genes_source.options[0:1]\n",
    "        if source not in i_reannotate_genes_source.options:\n",
    "            i_reannotate_genes_source.value = i_reannotate_genes_source.options[-1]\n",
    "        return None\n",
    "    elif mode == \"from uniprot fasta headers\":\n",
    "        stored = [el for el in pkg_resources.resource_listdir(\"domaps\", \"annotations/idmapping\") if el.endswith(\".txt\")]\n",
    "        i_reannotate_genes_source.options = i_reannotate_genes_source.options[0:1]+stored\n",
    "        if source not in i_reannotate_genes_source.options:\n",
    "            i_reannotate_genes_source.value = i_reannotate_genes_source.options[-1]\n",
    "    elif mode == \"from uniprot tab download\":\n",
    "        stored = [el for el in pkg_resources.resource_listdir(\"domaps\", \"annotations/idmapping\") if el.endswith(\".tab\")]\n",
    "        i_reannotate_genes_source.options = i_reannotate_genes_source.options[0:1]+stored\n",
    "        if source not in i_reannotate_genes_source.options:\n",
    "            i_reannotate_genes_source.value = i_reannotate_genes_source.options[-1]\n",
    "    else:\n",
    "        return f\"Reannotation mode {mode} is not implemented.\"\n",
    "    if source == i_reannotate_genes_source.options[0]:\n",
    "        return pn.Column(i_reannotate_genes_source, i_reannotate_genes_file)\n",
    "    else:\n",
    "        return i_reannotate_genes_source\n",
    "\n",
    "def execution(event):\n",
    "    if cache_uploaded.value == False:\n",
    "        analysis_status.object = \"Please upload a file first\"\n",
    "    elif i_expname.value == \"\":\n",
    "        analysis_status.object = \"Please enter an experiment name first\"\n",
    "    elif i_reannotate_genes_file.value == \"upload custom file\" and i_reannotate_genes_source.value is None:\n",
    "        analysis_status.object = \"Please upload your custom file for gene reannotation\"\n",
    "    else:\n",
    "        lo_config_instructions.collapsed = True\n",
    "        lo_read_file.collapsed = True\n",
    "        output_layoutpos = [el.name for el in dashboard_analysis].index(\"analysis_output\")\n",
    "        dashboard_analysis.objects[output_layoutpos].objects = []\n",
    "        cache_run.value = False\n",
    "        for wdgt in wdgts:\n",
    "            wdgt.disabled = True\n",
    "        #if you did already your comparison, but add another experiment afterwards - without reloading your\n",
    "        #AnylsedDatasets.json\n",
    "        try:\n",
    "            loading_status.objects = [loading]\n",
    "            analysis_status.object = \"Analysis in progress\"\n",
    "            \n",
    "            # get naming pattern\n",
    "            if i_name_pattern.value == \"Custom\":\n",
    "                namePattern = i_custom_namepattern.value\n",
    "            else:\n",
    "                namePattern = i_name_pattern.value\n",
    "            \n",
    "            # get gene reannotation\n",
    "            reannotation_source = {}\n",
    "            if i_reannotate_genes.value == \"don't reannotate\":\n",
    "                reannotate = False\n",
    "            else:\n",
    "                reannotate = True\n",
    "                if i_reannotate_genes.value == \"from uniprot.org\":\n",
    "                    reannotation_source[\"source\"] = \"uniprot\"\n",
    "                elif i_reannotate_genes.value == \"from uniprot fasta headers\":\n",
    "                    reannotation_source[\"source\"] = \"fasta_headers\"\n",
    "                    if i_reannotate_genes_source.value == \"upload custom file\":\n",
    "                        idmapping = [el.decode('UTF-8').strip()\n",
    "                                     for el in BytesIO(i_reannotate_genes_file.value).readlines()]\n",
    "                    else:\n",
    "                        idmapping = [el.decode('UTF-8').strip()\n",
    "                                     for el in pkg_resources.resource_stream(\n",
    "                            \"domaps\", 'annotations/idmapping/{}'.format(i_reannotate_genes_source.value)).readlines()]\n",
    "                    reannotation_source[\"idmapping\"] = idmapping\n",
    "                elif i_reannotate_genes.value == \"from uniprot tab download\":\n",
    "                    reannotation_source[\"source\"] = \"tsv\"\n",
    "                    if i_reannotate_genes_source.value == \"upload custom file\":\n",
    "                        idmapping = pd.read_csv(BytesIO(i_reannotate_genes_file.value), sep='\\t',\n",
    "                                                usecols=[\"Entry\", \"Gene names  (primary )\"])\n",
    "                    else:\n",
    "                        idmapping = pd.read_csv(pkg_resources.resource_stream(\n",
    "                            \"domaps\", 'annotations/idmapping/{}'.format(i_reannotate_genes_source.value)), sep='\\t',\n",
    "                                                usecols=[\"Entry\", \"Gene names  (primary )\"])\n",
    "                    reannotation_source[\"idmapping\"] = idmapping\n",
    "                else:\n",
    "                    raise ValueError(i_reannotate_genes.value)\n",
    "            \n",
    "            global i_class\n",
    "            if i_acquisition.value == \"SILAC\":\n",
    "                i_class = domaps.SpatialDataSet(i_file.filename, i_expname.value, i_acquisition.value,\n",
    "                                                comment=i_comment.value, name_pattern=namePattern,\n",
    "                                                organism=i_organism.value,\n",
    "                                                reannotate_genes=reannotate, reannotation_source=reannotation_source,\n",
    "                                                RatioHLcount=i_RatioHLcount.value,\n",
    "                                                RatioVariability=i_RatioVariability.value)\n",
    "            if i_acquisition.value == \"Custom\":\n",
    "                i_class = domaps.SpatialDataSet(i_file.filename, i_expname.value, i_acquisition.value,\n",
    "                                                comment=i_comment.value, name_pattern=namePattern,\n",
    "                                                organism=i_organism.value,\n",
    "                                                reannotate_genes=reannotate, reannotation_source=reannotation_source,\n",
    "                                                custom_columns = {\"ids\": i_custom_cids.value,\n",
    "                                                                  \"genes\": i_custom_cgenes.value,\n",
    "                                                                  \"data\": i_custom_cdata.value},\n",
    "                                                custom_normalized = i_custom_normalized.value)\n",
    "            else:\n",
    "                i_class = domaps.SpatialDataSet(i_file.filename, i_expname.value, i_acquisition.value,\n",
    "                                                comment=i_comment.value, name_pattern=namePattern,\n",
    "                                                organism=i_organism.value,\n",
    "                                                reannotate_genes=reannotate, reannotation_source=reannotation_source,\n",
    "                                                consecutiveLFQi=i_consecutiveLFQi.value,\n",
    "                                                summed_MSMS_counts=i_summed_MSMS_counts.value)\n",
    "            analysis_status.object = \"Data Reading\"\n",
    "            i_class.data_reading(content=BytesIO(i_file.value))\n",
    "            analysis_status.object = \"Data Processing\"\n",
    "            i_class.processingdf()\n",
    "            update_object_selector(i_mapwidget, i_clusterwidget)\n",
    "            i_class.quantity_profiles_proteinGroups()\n",
    "            analysis_status.object = \"PCA\"\n",
    "            i_class.perform_pca()\n",
    "            analysis_status.object = \"Calculating Manhattan Distance\"\n",
    "            i_class.calc_biological_precision()\n",
    "            analysis_status.object = \"Writing Overview Table\"\n",
    "            i_class.results_overview_table()\n",
    "            analysis_status.object = \"Writing Analysed Dataset Dictionary\"\n",
    "            loading_status.objects = []\n",
    "            analysis_status.object = \"Analysis finished!\"\n",
    "            dashboard_analysis.objects[output_layoutpos].append(i_clusterwidget)\n",
    "            dashboard_analysis.objects[output_layoutpos].append(i_mapwidget)\n",
    "            dashboard_analysis.objects[output_layoutpos].append(analysis_tabs)\n",
    "            mem_available_datasets[i_class.expname] = i_class.analysed_datasets_dict[i_class.expname]\n",
    "            try:\n",
    "                i_dfs_available.options.append(i_class.expname)\n",
    "                i_dfs_available.value.append(i_class.expname)\n",
    "                coll_activatebuttons(i_dfs_available.value)\n",
    "            except:\n",
    "                pass\n",
    "            cache_run.value = True\n",
    "        except:\n",
    "            for wdgt in wdgts:\n",
    "                wdgt.disabled = False\n",
    "            loading_status.objects = [\"\"]\n",
    "            #The traceback gives no traceback, so out of that there will be still the output: Analysis in progress, although it is not possible. Out of that i removed the traceback\n",
    "            analysis_status.object = traceback.format_exc()\n",
    "            cache_run.value = False\n",
    "button_analysis.on_click(execution)\n",
    "\n",
    "#### Callback output positioning\n",
    "#### File config\n",
    "################################\n",
    "lo_read_file.append(read_file)\n",
    "\n",
    "\n",
    "\n",
    "i_logOR01_selection = pn.widgets.Select(options=[\"0/1 normalized data\", \"log transformed data\",\n",
    "                                                 \"stringency filtered raw data\", \"Overview - cluster distances\"],\n",
    "                                        name=\"Select type of data for download\", width=300)\n",
    "\n",
    "i_clusterwidget = pn.widgets.Select(options=[\"Proteasome\", \"Lysosome\"], name=\"Cluster of interest\", width=300)\n",
    "i_mapwidget = pn.widgets.Select(options=[\"Map1\", \"Map2\"], name=\"Map of interest\", width=300)\n",
    "\n",
    "i_collapse_maps_PCA = pn.widgets.Checkbox(value=False, name=\"Collapse maps\")\n",
    "\n",
    "i_x_vs_yAxis_PCA = {\n",
    "    \"PC1\" : [\"PC3\", \"PC2\"],\n",
    "    \"PC2\" : [\"PC1\", \"PC3\"],\n",
    "    \"PC3\" : [\"PC1\", \"PC2\"],\n",
    "    }\n",
    "\n",
    "i_xAxis_PCA = pn.widgets.Select(name=\"X-Axis\", options=[\"PC1\", \"PC2\",\"PC3\"])\n",
    "i_yAxis_PCA = pn.widgets.Select(name=\"Y-Axis\", options=i_x_vs_yAxis_PCA[i_xAxis_PCA.value])\n",
    "\n",
    "i_xAxis_PCA_comp = pn.widgets.Select(name=\"X-Axis\", options=[\"PC1\", \"PC2\",\"PC3\"])\n",
    "i_yAxis_PCA_comp = pn.widgets.Select(name=\"Y-Axis\", options=i_x_vs_yAxis_PCA[i_xAxis_PCA_comp.value])\n",
    "\n",
    "@pn.depends(i_xAxis_PCA_comp.param.value, watch=True)\n",
    "def custimization_PCA_comp(xAxis_PCA_comp):\n",
    "    yAxis_PCA_comp = i_x_vs_yAxis_PCA[xAxis_PCA_comp]\n",
    "    i_yAxis_PCA_comp.options = yAxis_PCA_comp\n",
    "    #return i_yAxis_PCA_comp\n",
    "\n",
    "@pn.depends(i_xAxis_PCA.param.value, watch=True)\n",
    "def custimization_PCA(xAxis_PCA):\n",
    "    yAxis_PCA = i_x_vs_yAxis_PCA[xAxis_PCA]\n",
    "    i_yAxis_PCA.options = yAxis_PCA\n",
    "    #return i_yAxis_PCA\n",
    "        \n",
    "\n",
    "\n",
    "## Analysis tab\n",
    "\n",
    "def update_object_selector(i_mapwidget, i_clusterwidget):\n",
    "    i_mapwidget.options = list(i_class.map_names)\n",
    "    i_clusterwidget.options = list(i_class.markerproteins.keys())\n",
    "\n",
    "\n",
    "@pn.depends(i_mapwidget.param.value, cache_run.param.value, i_collapse_maps_PCA.param.value, i_clusterwidget.param.value, i_xAxis_PCA.param.value, i_yAxis_PCA.param.value)\n",
    "def update_data_overview(mapwidget, run, collapse_maps_PCA, clusterwidget, xAxis_PCA, yAxis_PCA):\n",
    "    try:\n",
    "        if run == True:\n",
    "            pca_plot = i_class.plot_global_pca(map_of_interest=mapwidget , cluster_of_interest=clusterwidget, x_PCA=xAxis_PCA, y_PCA=yAxis_PCA, collapse_maps=collapse_maps_PCA)\n",
    "            if i_acquisition.value != \"Custom\":\n",
    "                log_histogram = i_class.plot_log_data()\n",
    "            else:\n",
    "                log_histogram = \"\"\n",
    "            visualization_map = pn.Column(\n",
    "                    pn.Row(i_collapse_maps_PCA),\n",
    "                    pn.Row(pn.Pane(pca_plot, width=1000, config=plotly_config)),\n",
    "                    pn.Row(i_xAxis_PCA, i_yAxis_PCA),\n",
    "                    pn.Row(pn.Pane(log_histogram, width=1000, config=plotly_config))\n",
    "                    )\n",
    "            app_tabs.active = 1\n",
    "            return visualization_map\n",
    "        else:\n",
    "            visualization_map = \"Run analysis first!\"\n",
    "            return visualization_map\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "            \n",
    "\n",
    "@pn.depends(i_clusterwidget.param.value,i_mapwidget.param.value, cache_run.param.value)\n",
    "def update_cluster_overview(clusterwidget, mapwidget, run):\n",
    "    try:\n",
    "        if run == True:\n",
    "            list_genes = [goi for goi in i_class.genenames_sortedout_list if goi in i_class.markerproteins[clusterwidget]]\n",
    "            i_class.cache_cluster_quantified = True\n",
    "            distance_boxplot = i_class.distance_boxplot(cluster_of_interest=clusterwidget)\n",
    "            if i_class.cache_cluster_quantified == False:\n",
    "                return \"This protein cluster was not quantified\"\n",
    "            \n",
    "            else:\n",
    "                df_quantification_overview = i_class.quantification_overview(cluster_of_interest=clusterwidget)\n",
    "                profiles_plot = i_class.profiles_plot(map_of_interest = mapwidget, cluster_of_interest=clusterwidget)\n",
    "                pca_plot = i_class.plot_cluster_pca(cluster_of_interest=clusterwidget)\n",
    "                cluster_overview = pn.Column(\n",
    "                        pn.Row(pn.Pane(pca_plot, width=500, config=plotly_config),\n",
    "                               pn.Pane(profiles_plot, width=500, config=plotly_config),\n",
    "                               pn.Pane(distance_boxplot, width=500, config=plotly_config),\n",
    "                              ),\n",
    "                        pn.Row(pn.Pane(\"In total {} proteins across all maps were quantified, whereas the following proteins were not consistently quantified throughout all maps: {}\".format(\n",
    "                                i_class.proteins_quantified_across_all_maps, \", \".join(list_genes)) if len(list_genes) != 0 else\n",
    "                            \"All genes from this cluster are quantified in all maps.\"), width=1000),\n",
    "                        pn.Row(pn.widgets.DataFrame(df_quantification_overview, height=200, width=500, disabled=True))  \n",
    "                        )\n",
    "                return cluster_overview\n",
    "        \n",
    "        else:\n",
    "            cluster_overview = \"Run analysis first!\"\n",
    "            return cluster_overview\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "    \n",
    "    \n",
    "@pn.depends(i_clusterwidget.param.value, cache_run.param.value)\n",
    "def update_cluster_details(clusterwidget, run):\n",
    "    try:\n",
    "        if run == True:\n",
    "            cluster_details = i_class.distance_to_median_boxplot(cluster_of_interest = clusterwidget)\n",
    "            return pn.Pane(cluster_details, width=1000, config=plotly_config)\n",
    "        else:\n",
    "            cluster_details = \"Run analysis first!\"\n",
    "            return pn.Pane(cluster_details, width=1000)\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "    \n",
    "@pn.depends(cache_run.param.value)\n",
    "def update_quantity(run):\n",
    "    try:\n",
    "        if run == True:\n",
    "            fig_npg, fig_npr, fig_npr_dc, fig_npg_F, fig_npgf_F, fig_npg_F_dc = i_class.plot_quantity_profiles_proteinGroups()\n",
    "            return pn.Column(\n",
    "                    pn.Row(pn.Pane(fig_npg, config=plotly_config), pn.Pane(fig_npr, config=plotly_config), pn.Pane(fig_npr_dc, config=plotly_config)) ,\n",
    "                pn.Row(pn.Pane(fig_npg_F, config=plotly_config), pn.Pane(fig_npgf_F, config=plotly_config), pn.Pane(fig_npg_F_dc, config=plotly_config)))\n",
    "        else:\n",
    "            return \"Run analysis first!\"\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "\n",
    "\n",
    "@pn.depends(cache_run.param.value)\n",
    "def show_tabular_overview(run):\n",
    "    try:\n",
    "        if run == True:\n",
    "            content = pn.Column(\n",
    "                pn.widgets.DataFrame(pd.read_json(i_class.analysed_datasets_dict[i_expname.value][\"Overview table\"]), height=200, width=600, disabled=True),\n",
    "\n",
    "                i_logOR01_selection,\n",
    "                df01_download_widget,\n",
    "                pn.widgets.FileDownload(callback=json_download, filename=\"AnalysedDatasets.json\")\n",
    "            )\n",
    "            return pn.Row(content, width=1000)\n",
    "        else:\n",
    "            content = \"Please, upload a file first and press ‘Analyse clusters’\"\n",
    "            return pn.Row(content, width=1000)\n",
    "    except Exception:\n",
    "        content = traceback.format_exc()\n",
    "        return pn.Row(content, width=1000)\n",
    "\n",
    "@pn.depends(cache_run.param.value)\n",
    "def json_download(run):\n",
    "    sio = StringIO()\n",
    "    json.dump(\n",
    "        domaps.SpatialDataSetComparison.analysed_datasets_dict, \n",
    "        sio, \n",
    "        indent=4, \n",
    "        sort_keys=True\n",
    "    )\n",
    "    sio.seek(0)\n",
    "    return sio\n",
    "\n",
    "\n",
    "@pn.depends(cache_run.param.value, i_logOR01_selection.param.value)\n",
    "def df01_download_widget(run, logOR01_selection):\n",
    "    if logOR01_selection == \"0/1 normalized data\":\n",
    "        return pn.Column(pn.widgets.FileDownload(callback=df01_download, filename = \"01_normalized_data.csv\"), width=650) \n",
    "    if logOR01_selection == \"log transformed data\":\n",
    "        return pn.Column(pn.widgets.FileDownload(callback=dflog_download, filename = \"log_transformed_data.csv\"), width=650)\n",
    "    if logOR01_selection == \"Overview - cluster distances\":\n",
    "        return pn.Column(pn.widgets.FileDownload(callback=table_download, filename = \"cluster_distances.csv\"), width=650)  \n",
    "    else:\n",
    "        return pn.Column(pn.widgets.FileDownload(callback=df_filteredRawData_download, filename = \"stringency_filtered_raw_data.csv\"), width=650)\n",
    "\n",
    "    \n",
    "@pn.depends(cache_run.param.value)\n",
    "def df01_download(run):\n",
    "    df_01 = i_class.reframe_df_01ORlog_for_Perseus(i_class.df_01_stacked)\n",
    "    sio = StringIO()\n",
    "    df_01.to_csv(sio)\n",
    "    sio.seek(0)\n",
    "    return sio \n",
    "    \n",
    "    \n",
    "@pn.depends(cache_run.param.value)\n",
    "def dflog_download(run):\n",
    "    df_log = i_class.reframe_df_01ORlog_for_Perseus(i_class.df_log_stacked)\n",
    "    sio = StringIO()\n",
    "    df_log.to_csv(sio)\n",
    "    sio.seek(0)\n",
    "    return sio \n",
    "\n",
    "@pn.depends(cache_run.param.value)\n",
    "def df_filteredRawData_download(run):\n",
    "    df = i_class.reframe_df_01ORlog_for_Perseus(i_class.df_stringencyFiltered)\n",
    "    sio = StringIO()\n",
    "    df.to_csv(sio)\n",
    "    sio.seek(0)\n",
    "    return sio\n",
    "\n",
    "@pn.depends(cache_run.param.value)\n",
    "def table_download(run):\n",
    "    df = i_class.results_overview_table()\n",
    "    sio = StringIO()\n",
    "    df.to_csv(sio)\n",
    "    sio.seek(0)\n",
    "    return sio\n",
    "\n",
    "analysis_tabs.clear()\n",
    "analysis_tabs.append((\"Data overview\", update_data_overview))\n",
    "analysis_tabs.append((\"Depth and Coverage\", update_quantity))\n",
    "analysis_tabs.append((\"Cluster Overview\", update_cluster_overview))\n",
    "analysis_tabs.append((\"Cluster Details\", update_cluster_details))\n",
    "analysis_tabs.append((\"Download\", show_tabular_overview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison tab\n",
    "\n",
    "loading_status_comparison = pn.Row()\n",
    "idle_comparison = pn.indicators.LoadingSpinner(value=False, width=100, height=100, color=\"primary\")\n",
    "loading_comparison = pn.indicators.LoadingSpinner(value=True, width=100, height=100, color=\"primary\")\n",
    "\n",
    "cache_uploaded_json = pn.widgets.Checkbox(value=False)\n",
    "cache_run_json = pn.widgets.Checkbox(value=False)\n",
    "#button_comparison = pn.widgets.Button(name=\"Compare experiments\", width=50)\n",
    "#i_jsonFile = pn.widgets.FileInput(name=\"Upload JSON file for comparison\")\n",
    "i_multi_choice = pn.widgets.CrossSelector(name=\"Select experiments for comparison\", value=[\"a\", \"b\"],\n",
    "                                          options=[\"a\", \"b\", \"c\"], definition_order=False)\n",
    "i_scatter_metric = pn.widgets.Select(name=\"Distance metric\",\n",
    "                                     options=[\"manhattan distance to average profile\",\n",
    "                                              \"manhattan distance to median profile\",\n",
    "                                              \"euclidean distance\", \"manhattan distance\",\n",
    "                                              \"1 - cosine correlation\", \"1 - pearson correlation\",])\n",
    "i_scatter_consolidation = pn.widgets.Select(name=\"Consolidation of replicate distances\",\n",
    "                                            options=[\"average\",\"median\",\"sum\"])\n",
    "i_ref_exp = pn.widgets.Select(name=\"Select experiments as reference\", options=[\"a\", \"b\", \"c\"])\n",
    "i_collapse_cluster = pn.widgets.Checkbox(value=True, name=\"Collapse cluster\")\n",
    "comparison_status = pn.Pane(\"No datasets were compared yet\")\n",
    "i_markerset_or_cluster = pn.widgets.Checkbox(value=False, name=\"Display only protein clusters\")\n",
    "#i_ranking_boxPlot = pn.widgets.Checkbox(value=False, name=\"Display box plot\")\n",
    "i_ranking_boxPlot = pn.widgets.RadioBoxGroup(name=\"Types of ranking\", options=[\"Box plot\", \"Bar plot - median\", \"Bar plot - sum\"], inline=True)\n",
    "#i_toggle_sumORmedian = pn.widgets.Toggle(name=\"Sum or Median\", button_type=\"primary\")\n",
    "i_clusterwidget_comparison = pn.widgets.Select(options=[], name=\"Cluster of interest\", width=300)\n",
    "i_ExpOverview = pn.Row(pn.Pane(\"\", width=1000))\n",
    "i_include_dataset = pn.widgets.Checkbox(value=False, name=\"Include data analysed under 'Analysis' tab\")\n",
    "i_compare_gene = pn.widgets.TextInput(value=\"PLEC\", name=\"Enter gene name or protein ID to see profile.\")\n",
    "i_compare_profile_style = pn.widgets.Select(options=[\n",
    "    #\"all profiles\",\n",
    "    \"mean +- stdev\", \"mean +- SEM\"])\n",
    "i_compare_compartment = pn.widgets.MultiSelect(options=[], name=\"Select compartments for which to show summary profiles.\")\n",
    "#wdgts_comparison = [button_comparison]#,i_organism_comparison]#, i_include_dataset] \n",
    "json_dict = {}\n",
    "json_exp_name_cache = []\n",
    "\n",
    "\n",
    "\n",
    "#@pn.depends(cache_run.param.value, i_jsonFile.param.value)#cache_run.param.value\n",
    "#def open_jsonFile(run, jsonFile):#run\n",
    "#    cache_run_json.value = False\n",
    "#    if run == False and jsonFile is None:\n",
    "#        filereading_status_json = \"No file is uploaded\"\n",
    "#        cache_uploaded_json.value = False\n",
    "#        return filereading_status_json\n",
    "#    else:\n",
    "#        try:\n",
    "#            if run == True:\n",
    "#                global json_dict\n",
    "#                json_dict.update(domaps.SpatialDataSet.analysed_datasets_dict)\n",
    "#            if jsonFile != None:\n",
    "#                global json_exp_name_cache\n",
    "#                if cache_uploaded_json.value==False:\n",
    "#                    json_dict.update(json.load(BytesIO(jsonFile)))\n",
    "#                    json_exp_name_cache = list(json.load(BytesIO(jsonFile)).keys())\n",
    "#                else:\n",
    "#                    for key in json_exp_name_cache:\n",
    "#                        del json_dict[key]\n",
    "#                    json_dict.update(json.load(BytesIO(jsonFile)))\n",
    "#                    json_exp_name_cache = list(json.load(BytesIO(jsonFile)).keys())\n",
    "#                    \n",
    "#            #    except:\n",
    "#            #        pass\n",
    "#            #elif jsonFile is not None:\n",
    "#            #    if i_include_dataset.value == False:\n",
    "#            #        json_dict = json.load(BytesIO(jsonFile))\n",
    "#            #    else:\n",
    "#            #        #global json_dict\n",
    "#            #        json_dict.update(json.load(BytesIO(jsonFile))) #i_class.\n",
    "#            try:\n",
    "#                dashboard_comparison.objects = dashboard_comparison.objects[0:4]\n",
    "#            except:\n",
    "#                pass\n",
    "#            if hasattr(json_dict, \"keys\") == False: #i_class.\n",
    "#                return \"Your json-File does not fulfill the requirements\"\n",
    "#            else:\n",
    "#                i_multi_choice.options = []\n",
    "#                filereading_status_json = list(json_dict.keys())# list(set(list(SpatialDataSet.analysed_datasets_dict.keys()) + )) #i_class.\n",
    "#                cache_uploaded_json.value = True\n",
    "#                for wdgt in wdgts_comparison:\n",
    "#                    wdgt.disabled = False\n",
    "#                return pn.Column(pn.Row(\"Experiments for comparison: {}\".format(\", \".join(filereading_status_json[:]))),\n",
    "#                                 #pn.Row(i_include_dataset),\n",
    "#                                 #pn.Row(i_organism_comparison),\n",
    "#                                 pn.Row(button_comparison),\n",
    "#                                 )\n",
    "#        \n",
    "#        except Exception: \n",
    "#            filereading_status_json = traceback.format_exc()\n",
    "#            cache_uploaded_json.value = False\n",
    "#            return filereading_status_json                 \n",
    "\n",
    "@pn.depends(i_multi_choice.param.value, i_clusterwidget_comparison.param.value, cache_run_json.param.value, i_xAxis_PCA_comp.param.value, i_yAxis_PCA_comp.param.value, \n",
    "            i_markerset_or_cluster.param.value)\n",
    "def update_visualization_map_comparison(multi_choice, clusterwidget_comparison, run_json, xAxis_PCA_comp, yAxis_PCA_comp, markerset_or_cluster):\n",
    "    try:\n",
    "        if run_json == True:\n",
    "            if multi_choice == []:\n",
    "                return pn.Column(#pn.Row(i_multi_choice),\n",
    "                                 pn.Row(\"Please select experiments for comparison\")\n",
    "                                )\n",
    "            else:\n",
    "                pass\n",
    "            pca_global_comparison = i_class_comp.plot_global_pca_comparison(cluster_of_interest_comparison=clusterwidget_comparison, x_PCA=xAxis_PCA_comp, y_PCA=yAxis_PCA_comp, \n",
    "                                                                       markerset_or_cluster=markerset_or_cluster, multi_choice=multi_choice)\n",
    "            if markerset_or_cluster == False:\n",
    "                return pn.Column(#pn.Row(i_multi_choice),\n",
    "                                 pn.Row(i_clusterwidget_comparison),\n",
    "                                 pn.Row(i_markerset_or_cluster),\n",
    "                                 pn.Pane(pca_global_comparison, config=plotly_config),\n",
    "                                 pn.Row(i_xAxis_PCA_comp, i_yAxis_PCA_comp)  \n",
    "                                )\n",
    "            else:\n",
    "                return pn.Column(#pn.Row(i_multi_choice),\n",
    "                                 pn.Row(i_markerset_or_cluster),\n",
    "                                 pn.Pane(pca_global_comparison, config=plotly_config),\n",
    "                                 pn.Row(i_xAxis_PCA_comp, i_yAxis_PCA_comp)   \n",
    "                                )\n",
    "        else:\n",
    "            pca_global_comparison = \"Run analysis first!\"\n",
    "            return pca_global_comparison\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "\n",
    "#### Biological precision tab\n",
    "## Widgets\n",
    "i_clusters_for_ranking = pn.widgets.CrossSelector(name=\"Select clusters to be considered for ranking calculation\",\n",
    "                                                  options=[], size=8)\n",
    "i_minn_proteins = pn.widgets.IntSlider(name=\"Minimum number of proteins per complex\", start=3, end=13, step=1, value=5)\n",
    "i_collapse_maps = pn.widgets.Checkbox(value=False, name=\"Collapse maps\")\n",
    "i_reference_map = pn.widgets.Select(options=[], value=\"\", name=\"Select reference map\")\n",
    "\n",
    "## Callbacks\n",
    "@pn.depends(i_multi_choice.param.options, i_minn_proteins.param.value, cache_run_json.param.value)\n",
    "def update_comp_cluster_coverage(exp_names, min_n, run_json):\n",
    "    try:\n",
    "        if not run_json:\n",
    "            return \"\"\n",
    "        [f,p,n] = i_class_comp.get_complex_coverage(min_n)\n",
    "        i_clusters_for_ranking.options = [el for el in i_class_comp.markerproteins.keys() if el not in n.keys()]\n",
    "        i_clusterwidget_comparison.options = [el for el in i_class_comp.markerproteins.keys() if el not in n.keys()]\n",
    "        i_clusters_for_ranking.value = [el for el in i_class_comp.markerproteins.keys() if el in f.keys()]\n",
    "        return pn.Row(\n",
    "            \"Coverage in all experiments \\[>= n proteins]:<br>\"+\"<br>\".join([\"- {} ({})\".format(k,v) for k,v in f.items()]),\n",
    "            \"Coverage in some experiments \\[proteins/experiment]:<br>\"+\"<br>\".join([\"- {} \\{}\".format(k,str(v)) for k,v in p.items()]),\n",
    "            \"No sufficient coverage in any experiment \\[proteins/experiment]:<br>\"+\"<br>\".join([\"- {} \\{}\".format(k,str(v)) for k,v in n.items()])\n",
    "        )\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "\n",
    "@pn.depends(i_multi_choice.param.value, i_clusters_for_ranking.param.value, i_reference_map.param.value,\n",
    "            i_minn_proteins.param.value, cache_run_json.param.value)\n",
    "def update_comp_bp_global(multi_choice, clusters_for_ranking, reference_map, min_n, run_json):\n",
    "    try:\n",
    "        if not run_json:\n",
    "            return \"\"\n",
    "        if set(multi_choice) != set(i_class_comp.df_distance_comp.Experiment.values):\n",
    "            i_class_comp.calc_biological_precision(multi_choice)\n",
    "            i_reference_map.options = multi_choice\n",
    "            if reference_map not in multi_choice:\n",
    "                i_reference_map.value = multi_choice[0]\n",
    "                reference_map = multi_choice[0]\n",
    "        if clusters_for_ranking == []:\n",
    "            return \"Select at least one cluster\"\n",
    "        else:\n",
    "            bp_bargraph, bp_boxplot_abs, bp_boxplot_rel = i_class_comp.plot_biological_precision(\n",
    "                multi_choice, clusters_for_ranking, min_members=min_n, reference = reference_map)\n",
    "            return pn.Column(\n",
    "                pn.Row(i_reference_map),\n",
    "                pn.Row(pn.Pane(bp_bargraph, config=plotly_config),\n",
    "                       pn.Pane(bp_boxplot_abs, config=plotly_config),\n",
    "                       pn.Pane(bp_boxplot_rel, config=plotly_config)))\n",
    "        \n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "\n",
    "@pn.depends(i_multi_choice.param.value, i_clusterwidget_comparison.param.value, i_collapse_maps.param.value,\n",
    "            cache_run_json.param.value)\n",
    "def update_comp_bp_single(multi_choice, clusterwidget_comparison, collapse_maps, run_json):\n",
    "    try:\n",
    "        i_class_comp.cache_cluster_quantified = True\n",
    "        distance_comparison = i_class_comp.distance_boxplot_comparison(collapse_maps=collapse_maps, cluster_of_interest_comparison=clusterwidget_comparison, multi_choice=multi_choice)\n",
    "        if i_class_comp.cache_cluster_quantified == False:\n",
    "            return \"Cluster was not quantified in any experiment\"\n",
    "        else:\n",
    "            pca_comparison = i_class_comp.plot_pca_comparison(cluster_of_interest_comparison=clusterwidget_comparison, multi_choice=multi_choice)\n",
    "            return pn.Row(pn.Pane(pca_comparison, config=plotly_config),\n",
    "                          pn.Pane(distance_comparison, config=plotly_config))\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "\n",
    "## Tab assembly\n",
    "comparison_tab_bp = pn.Column(\n",
    "    pn.Row(pn.Column(i_clusters_for_ranking,i_minn_proteins),\n",
    "           update_comp_cluster_coverage),\n",
    "    update_comp_bp_global,\n",
    "    pn.Row(i_clusterwidget_comparison,i_collapse_maps),\n",
    "    update_comp_bp_single\n",
    ")\n",
    "    \n",
    "@pn.depends(i_multi_choice.param.value, cache_run_json.param.value)\n",
    "def update_npr_ngg_nprDc(multi_choice, run_json):\n",
    "    try:\n",
    "        if run_json == True: \n",
    "            if multi_choice == []:\n",
    "                return pn.Column(\n",
    "                                 pn.Row(\"Please select experiments for comparison\"))\n",
    "            else:\n",
    "                fig_quantity_pg, fig_quantity_pr = i_class_comp.quantity_pr_pg_barplot_comparison(multi_choice=multi_choice)\n",
    "                coverage_barplot = i_class_comp.coverage_comparison(multi_choice=multi_choice)\n",
    "                return pn.Row(pn.Column(\n",
    "                                 pn.Pane(fig_quantity_pg, config=plotly_config), \n",
    "                                 #pn.Pane(fig_quantity_pr, config=plotly_config), #removed for now, as the added information is not a lot\n",
    "                                 pn.Pane(coverage_barplot, config=plotly_config)\n",
    "                                ))\n",
    "        else:\n",
    "            completeness_barplot = \"Run analysis first!\"\n",
    "            return completeness_barplot\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status \n",
    "    \n",
    "@pn.depends(i_multi_choice.param.value, cache_run_json.param.value)\n",
    "def update_venn(multi_choice, run_json):\n",
    "    try:\n",
    "        if run_json == True: \n",
    "            venn_plot = []\n",
    "            if len(multi_choice)<=1:\n",
    "                return pn.Column(\n",
    "                    pn.Row(pn.Pane(\"Please select 2 or more experiments for comparison\"), width=1000))\n",
    "            else:\n",
    "                venn_plot_total, venn_plot_int, figure_UpSetPlot_total, figure_UpSetPlot_int = i_class_comp.venn_sections(multi_choice_venn = multi_choice)\n",
    "                return pn.Row(\n",
    "                    pn.Column(\n",
    "                        \"Proteins quantified in at least one map\",\n",
    "                        pn.Pane(venn_plot_total),\n",
    "                        pn.Row(figure_UpSetPlot_total,width=1000)\n",
    "                    ),\n",
    "                    pn.Column(\n",
    "                        \"Proteins quantified in all maps\",\n",
    "                        pn.Pane(venn_plot_int),\n",
    "                        pn.Row(figure_UpSetPlot_int,width=1000)\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            venn_plot = \"Run analysis first!\"\n",
    "            return venn_plot\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status    \n",
    "\n",
    "# Vincent\n",
    "#### Dashboard structure\n",
    "#### SMV analysis\n",
    "########################\n",
    "lo_benchmark_SVMs = pn.Column(\n",
    "    pn.Card(header=\"###Add misclassification matrix\", name=\"add_mcmatrix\"),\n",
    "    pn.Row(name=\"svm_output\")\n",
    ")\n",
    "\n",
    "#### Layout elements\n",
    "#### SVM analysis\n",
    "####################\n",
    "lo_SVM_heatmap = pn.Column(\"Heatmap:\")\n",
    "\n",
    "#### Append layout to dashboard\n",
    "#### SVM analysis\n",
    "###############################\n",
    "for el in [lo_SVM_heatmap]:\n",
    "    lo_benchmark_SVMs.objects[[el.name for el in lo_benchmark_SVMs.objects].index(\"add_mcmatrix\")].append(el)\n",
    "\n",
    "#### Callbacks\n",
    "#### SVM analysis\n",
    "##############\n",
    "# add_SVM_result # mockup\n",
    "# fill_svm_comment # mockup\n",
    "# show_misclassification # mockup\n",
    "# update_SVM_Analysis # needs update, including the backend function in domaps.py\n",
    "\n",
    "def add_SVM_result():\n",
    "    \"\"\"\n",
    "    Adds SVM matrix uploaded in the tool to memory and to the current analysis\n",
    "    \"\"\"\n",
    "    # 1. Get input from interface\n",
    "    experiment, matrix, comment = None\n",
    "    \n",
    "    # 2. Add to i_class_comp\n",
    "    # defaults to name=\"default\" and overwrite=True\n",
    "    i_class_comp.add_SVM_result(experiment, matrix, comment=comment)\n",
    "    \n",
    "    # 3. Add to mem_available_datasets so it can be downloaded together with the data\n",
    "    mem_available_datasets[experiment][\"SVM results\"] = i_class_comp.svm_results[experiment]\n",
    "    \n",
    "    # 4. Trigger update of figure\n",
    "#btn_SVM_addmatrix.onclick(add_SVM_result)\n",
    "\n",
    "#@pn.depends(matrix, watch=True)\n",
    "def fill_svm_comment(matrix):\n",
    "    \"\"\"\n",
    "    Fill the comment field with a reasonable default comment.\n",
    "    \"\"\"\n",
    "    comment.value = \"Matrix added on {date} at {time}\"\n",
    "\n",
    "#pn.depends(experiment, matrix)\n",
    "def show_misclassification(experiment, matrix):\n",
    "    \"\"\"\n",
    "    Display heatmap of freshly uploaded or reloaded SVM misclassification matrix\n",
    "    \"\"\"\n",
    "    #domaps.svm_heatmap()\n",
    "    #return plotly figure\n",
    "\n",
    "\n",
    "@pn.depends(i_multi_choice.param.value, cache_run_json.param.value)\n",
    "def update_SVM_Analysis(multi_choice, run_json):\n",
    "    try:\n",
    "        if run_json == True: \n",
    "            if multi_choice == []:\n",
    "                return pn.Column(\n",
    "                                 pn.Row(\"Please select experiments for comparison\"))\n",
    "            else:\n",
    "                if i_class_comp.cache_stored_SVM == False:\n",
    "                    return pn.Column(\n",
    "                                 pn.Row(\"No Missclassifiaction Matrix is stored\"))\n",
    "                else:\n",
    "                    fig_markerPredictionAccuracy, fig_clusterPerformance = i_class_comp.svm_plotting(multi_choice)\n",
    "                    return pn.Column(\n",
    "                                 pn.Pane(fig_markerPredictionAccuracy, config=plotly_config),\n",
    "                                 pn.Pane(fig_clusterPerformance, config=plotly_config), \n",
    "                                 pn.Row(pn.Pane(\"\", width=1000)),\n",
    "                    )\n",
    "                \n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status \n",
    "\n",
    "#### Callback output positioning\n",
    "#### SVM analysis\n",
    "################################\n",
    "#lo_SVM_heatmap.append(show_misclassification)\n",
    "lo_benchmark_SVMs.objects[[el.name for el in lo_benchmark_SVMs.objects].index(\"svm_output\")].append(update_SVM_Analysis)\n",
    "# End Vincent\n",
    "\n",
    "\n",
    "@pn.depends(i_multi_choice.param.value, i_scatter_metric.param.value, i_scatter_consolidation.param.value,\n",
    "            cache_run_json.param.value)\n",
    "def update_global_scatter_comparison(multi_choice, metric, consolidation, run_json):\n",
    "    try:\n",
    "        if run_json == True: \n",
    "            if multi_choice == []:\n",
    "                return pn.Column(#pn.Row(i_multi_choice),\n",
    "                                 pn.Row(\"Please select experiments for comparison\"))\n",
    "            else:\n",
    "                scatter_histogram = i_class_comp.calculate_global_scatter(multi_choice=multi_choice,\n",
    "                                                                              metric=metric, consolidation=consolidation)\n",
    "                return pn.Column(pn.Row(i_scatter_metric),\n",
    "                                 pn.Row(i_scatter_consolidation),\n",
    "                                 pn.Pane(scatter_histogram, config=plotly_config)\n",
    "                                )\n",
    "        else:\n",
    "            return \"Run analysis first!\"\n",
    "    except Exception:\n",
    "        update_status = traceback.format_exc()\n",
    "        return update_status\n",
    "\n",
    "@pn.depends(i_multi_choice.param.value, i_compare_gene.param.value, i_compare_compartment.param.value,\n",
    "            i_compare_profile_style.param.value, cache_run_json.param.value)\n",
    "def update_profile_comparison(multi_choice, compare_gene, compare_compartment, compare_profile_style, run_json):\n",
    "    if not run_json:\n",
    "        return \"Run analysis first!\"\n",
    "    try:\n",
    "        try:\n",
    "            plotdata = i_class_comp.df_01_filtered_combined.xs(compare_gene,level=\"Gene names\",\n",
    "                                                               axis=0, drop_level=False)\\\n",
    "                                   .stack(\"Fraction\").reset_index().rename({0:\"Profile [% total signal]\"}, axis=1)\n",
    "        except:\n",
    "            try:\n",
    "                plotdata = i_class_comp.df_01_filtered_combined.xs(compare_gene,level=\"Protein IDs\",\n",
    "                                                                   axis=0, drop_level=False)\\\n",
    "                                       .stack(\"Fraction\").reset_index().rename({0:\"Profile [% total signal]\"}, axis=1)\n",
    "            except:\n",
    "                try:\n",
    "                    plotdata = i_class_comp.df_01_filtered_combined.loc[[\n",
    "                        compare_gene in \" \".join(el) for el in i_class_comp.df_01_filtered_combined.index.values],:]\\\n",
    "                                           .stack(\"Fraction\").reset_index().rename({0:\"Profile [% total signal]\"}, axis=1)\n",
    "                except:\n",
    "                    plotdata = pd.DataFrame()\n",
    "        if len(plotdata) > 0:\n",
    "            plotdata.drop(\"Exp_Map\", axis=1, inplace=True)\n",
    "            plotdata.sort_values(\"Fraction\", key=domaps.natsort_list_keys, inplace=True)\n",
    "            experiments = [el for el in multi_choice if el in plotdata[\"Experiment\"].values]\n",
    "            plotdata = plotdata.set_index(\"Experiment\").loc[experiments,:].reset_index()\n",
    "            plotprofile = px.line(plotdata, x=\"Fraction\", y=\"Profile [% total signal]\", line_group=\"Map\",\n",
    "                                  facet_col=\"Protein IDs\", template=\"simple_white\",\n",
    "                                  line_dash = \"Sequence\" if \"Sequence\" in plotdata.columns else None,\n",
    "                                  color=\"Experiment\", hover_data=list(plotdata.columns))\n",
    "        else:\n",
    "            plotprofile = \"No gene or protein ID matching {} found.\".format(compare_gene)\n",
    "        \n",
    "        plotdata = pd.DataFrame()\n",
    "        if compare_profile_style == \"all profiles\":\n",
    "            for el in compare_compartment:\n",
    "                el_df = i_class_comp.df_01_filtered_combined.xs(el, level=\"Compartment\", axis=0, drop_level=False)\\\n",
    "                .stack(\"Fraction\").reset_index().rename({0:\"Profile [% total signal]\"}, axis=1)\n",
    "                plotdata = plotdata.append(el_df)\n",
    "            if len(plotdata) > 0:\n",
    "                plotdata.sort_values(\"Fraction\", key=domaps.natsort_list_keys, inplace=True)\n",
    "                plotdata = plotdata.set_index(\"Experiment\").loc[multi_choice,:].reset_index()\n",
    "                plotdata.insert(0, \"PG_Map\", [str(p)+\"_\"+str(m) for p,m in zip(plotdata[\"Protein IDs\"], plotdata[\"Map\"])])\n",
    "                plotcompartments = px.box(plotdata, x=\"Fraction\", y=\"Profile [% total signal]\", color=\"Experiment\",\n",
    "                                          facet_row=\"Compartment\", template=\"simple_white\")\n",
    "            else:\n",
    "                plotcompartments = \"Please select at least one compartment\"\n",
    "        else:\n",
    "            for el in compare_compartment:\n",
    "                el_df = i_class_comp.df_01_filtered_combined.xs(el, level=\"Compartment\", axis=0, drop_level=False)\n",
    "                plotdata = plotdata.append(el_df.stack(\"Fraction\").groupby([\"Compartment\", \"Map\", \"Experiment\", \"Fraction\"])\\\n",
    "                    .apply(lambda x: pd.Series({\"Profile [% total signal]\": np.nanmean(x), \"std\":np.nanstd(x),\n",
    "                                                \"sem\":np.nanstd(x)/np.sqrt(sum(np.isfinite(x)))}))\\\n",
    "                    .reset_index().rename(columns={\"level_4\": \"measure\", 0: \"value\"})\\\n",
    "                    .set_index([\"Compartment\", \"Map\", \"Experiment\", \"Fraction\", \"measure\"]).unstack(\"measure\")\\\n",
    "                    .droplevel(0, axis=1).reset_index())\n",
    "            if len(plotdata) > 0:\n",
    "                plotdata.sort_values(\"Fraction\", key=domaps.natsort_list_keys, inplace=True)\n",
    "                plotdata = plotdata.set_index(\"Experiment\").loc[multi_choice,:].reset_index()\n",
    "                plotcompartments = px.line(plotdata, x=\"Fraction\", y=\"Profile [% total signal]\", color=\"Experiment\",\n",
    "                                           line_group=\"Map\", line_dash=\"Compartment\", template=\"simple_white\",\n",
    "                                           error_y=\"std\" if \"stdev\" in compare_profile_style else \"sem\")\n",
    "            else:\n",
    "                plotcompartments = \"Please select at least one compartment\"\n",
    "        \n",
    "        return pn.Row(pn.Column(i_compare_gene,\n",
    "                                pn.Pane(plotprofile, config=plotly_config)),\n",
    "                      pn.Column(pn.Row(i_compare_compartment, i_compare_profile_style),\n",
    "                                pn.Pane(plotcompartments, config=plotly_config)))\n",
    "    except Exception:\n",
    "        return pn.Row(pn.Column(i_compare_gene,\n",
    "                                traceback.format_exc()),\n",
    "                      pn.Column(pn.Row(i_compare_compartment, i_compare_profile_style)))\n",
    "\n",
    "\n",
    "def update_multi_choice(i_multi_choice, i_clusterwidget, i_clusters_for_ranking):\n",
    "    i_multi_choice.options = i_class_comp.exp_names\n",
    "    i_reference_map.options = i_class_comp.exp_names\n",
    "    i_clusterwidget.options = list(i_class_comp.markerproteins.keys())\n",
    "    i_clusters_for_ranking.options = list(i_class_comp.markerproteins.keys())\n",
    "    i_clusters_for_ranking.value = list(i_class_comp.markerproteins.keys())\n",
    "    i_multi_choice.value = i_class_comp.exp_names\n",
    "    i_reference_map.value = i_class_comp.exp_names[0]\n",
    "\n",
    "    \n",
    "@pn.depends(i_multi_choice.param.value, watch=True)\n",
    "def update_ref_exp(multi_choice):\n",
    "    i_ref_exp.options = i_multi_choice.value\n",
    "    #return i_ref_exp\n",
    "\n",
    "\n",
    "@pn.depends(i_multi_choice.param.value, watch=True)\n",
    "def update_ExpOverview(multi_choice):\n",
    "    dict_analysis_parameters={}\n",
    "    for exp_name in multi_choice:\n",
    "        dict_analysis_parameters[exp_name] = i_class_comp.json_dict[exp_name][\"Analysis parameters\"]\n",
    "    i_ExpOverview[0] = pn.widgets.DataFrame(pd.DataFrame.from_dict(dict_analysis_parameters))\n",
    "    i_ExpOverview.value = pd.DataFrame.from_dict(dict_analysis_parameters)\n",
    "    i_ExpOverview.disabled = True\n",
    "    i_ExpOverview.height = 300\n",
    "\n",
    "    \n",
    "#def execution_comparison(event):\n",
    "#    if cache_uploaded_json.value == False:\n",
    "#        comparison_status.object = \"Please upload a JSON-file first\"\n",
    "#    else:        \n",
    "#        #dashboard_comparison.objects[2:] = []\n",
    "#        cache_run_json.value = False\n",
    "#        for wdgt in wdgts_comparison:\n",
    "#            wdgt.disabled = True\n",
    "#        try:\n",
    "#            loading_status_comparison.objects = [loading_comparison]\n",
    "#            comparison_status.object = \"Analysis in progress\"\n",
    "#            #protein_cluster = SpatialDataSet.markerproteins_set[i_organism_comparison.value].keys()\n",
    "#            update_ref_exp(i_ref_exp)\n",
    "#            global i_class_comp\n",
    "#            comparison_status.object = \"Initialization\"\n",
    "#            i_class_comp = domaps.SpatialDataSetComparison(ref_exp=i_ref_exp.value)#, clusters_for_ranking=protein_cluster, organism=i_organism_comparison.value)\n",
    "#            i_class_comp.json_dict = json_dict\n",
    "#            comparison_status.object = \"Reading\"\n",
    "#            i_class_comp.read_jsonFile()\n",
    "#            i_class_comp.calc_biological_precision()\n",
    "#            i_class_comp.get_complex_coverage()\n",
    "#            update_multi_choice(i_multi_choice, i_clusterwidget_comparison, i_clusters_for_ranking)\n",
    "#            i_compare_compartment.options = list(set(\n",
    "#                i_class_comp.df_01_filtered_combined.index.get_level_values(\"Compartment\")))\n",
    "#            comparison_status.object = \"SVM Processing\"\n",
    "#            i_class_comp.svm_processing()\n",
    "#            comparison_status.object = \"PCA\"\n",
    "#            i_class_comp.perform_pca_comparison()\n",
    "#            dashboard_comparison.append(pn.Row(i_multi_choice, i_ExpOverview))\n",
    "#            dashboard_comparison.append(comparison_tabs)\n",
    "#            loading_status_comparison.objects = []\n",
    "#            comparison_status.object = \"Comparison finished!\"\n",
    "#            cache_run_json.value = True\n",
    "#        except Exception:\n",
    "#            loading_status_comparison.objects = [\"\"]\n",
    "#            for wdgt in wdgts_comparison:\n",
    "#                wdgt.disabled = False\n",
    "#            comparison_status.object = traceback.format_exc()\n",
    "#            cache_run_json.value = False\n",
    "#button_comparison.on_click(execution_comparison)\n",
    "\n",
    "comparison_tabs.clear()\n",
    "comparison_tabs.append((\"Data Overview\", update_visualization_map_comparison))\n",
    "comparison_tabs.append((\"Depth and Coverage\", update_npr_ngg_nprDc))\n",
    "comparison_tabs.append((\"Unique and shared protein groups\", update_venn))\n",
    "comparison_tabs.append((\"Global Scatter\", update_global_scatter_comparison))\n",
    "comparison_tabs.append((\"Biological Precision\", comparison_tab_bp))\n",
    "comparison_tabs.append((\"SVM Analysis\", lo_benchmark_SVMs))\n",
    "comparison_tabs.append((\"Compare profiles\", update_profile_comparison))\n",
    "comparison_tabs.append((\"Download data\", \"Here I will add data download options\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_benchmark.objects = [\n",
    "    pn.Card(objects=[], header=\"## Manage data\", name=\"manage_data\", height_policy=\"fit\"),\n",
    "    pn.Row(objects=[], name=\"benchmark_output\", height_policy=\"fit\")\n",
    "]\n",
    "\n",
    "#### Manage data Card layout\n",
    "# This accesses mem_available_datasets and mem_benchmark.\n",
    "####\n",
    "\n",
    "## Adding datasets row\n",
    "i_upload_collection = pn.widgets.FileInput(name=\"Upload collection\")\n",
    "btn_load_reference = pn.widgets.Button(name=\"Load\", width=100, disabled=True)\n",
    "i_load_reference = pn.widgets.Select(options=[\n",
    "    \"HeLa DIA 100 min\",\n",
    "    \"HeLa SILAC Elife 2016\",\n",
    "    \"HeLa DIA 21 min\",\n",
    "    \"HeLa DIA 100 min triple shot\"], value=None, width=200)\n",
    "lo_add_datasets = pn.Row(objects=[\n",
    "    \"**Upload collection from file (.json):**\", i_upload_collection,\n",
    "    \"**Add reference set:**\", i_load_reference, btn_load_reference\n",
    "])\n",
    "\n",
    "## Selection checkbox\n",
    "i_dfs_available = pn.widgets.CheckBoxGroup(options=[], value=[],\n",
    "                                           name=\"Datasets available\")\n",
    "lo_dfs_available = pn.WidgetBox(objects=[\"**Datasets available**\", i_dfs_available], width=250)\n",
    "\n",
    "## Management button group\n",
    "btn_coll_downloadjson = pn.widgets.Button(name=\"Download selected as collection (.json)\", disabled=True) # move from analysis\n",
    "btn_coll_editnames = pn.widgets.Button(name=\"Edit names and comments\", disabled=True) # move from management\n",
    "btn_coll_reannotate = pn.widgets.Button(name=\"Reannotate genes/organelles/complexes\", disabled=True) # new functionality\n",
    "btn_coll_runmain = pn.widgets.Button(name=\"Align and analyse selected datasets\",\n",
    "                                     button_type=\"success\", disabled=True) # change from main comparison\n",
    "btn_coll_dropmem = pn.widgets.Button(name=\"Drop selected datasets from memory\",\n",
    "                                     button_type=\"danger\", disabled=True) # move from top of page\n",
    "lo_coll_buttons = pn.WidgetBox(objects=[\n",
    "    btn_coll_downloadjson,\n",
    "    btn_coll_editnames,\n",
    "    btn_coll_reannotate,\n",
    "    btn_coll_runmain,\n",
    "    btn_coll_dropmem\n",
    "], width=300)\n",
    "\n",
    "## Interaction pane\n",
    "lo_instructions_datamanagement = pn.Card(pn.pane.Markdown(textfragments[\"coll_status_default\"]),\n",
    "                                         header=\"**Explanation**\", width=400)\n",
    "o_status_datamanagement = pn.pane.Markdown(width=400)\n",
    "def set_status_datamanagement(x, append=False):\n",
    "    if not append:\n",
    "        o_status_datamanagement.object = x+\"<br><br>\"\n",
    "    else:\n",
    "        o_status_datamanagement.object += x+\"<br><br>\"\n",
    "    if x.startswith(\"Traceback\") or o_status_datamanagement.object.count(\"<br><br>\") > 1:\n",
    "        resize(dashboard_benchmark.objects[[i.name for i in dashboard_benchmark].index(\"manage_data\")])\n",
    "    if DEBUG:\n",
    "        time.sleep(0.3)\n",
    "\n",
    "set_status_datamanagement(\"Step 1: Add datasets\")\n",
    "o_dynamic_collectionmanagement = pn.Row()\n",
    "lo_coll_interactions = pn.Column(objects=[lo_instructions_datamanagement,\n",
    "                                          o_status_datamanagement,\n",
    "                                          o_dynamic_collectionmanagement])\n",
    "\n",
    "## Assemble collection management row\n",
    "lo_manage_collection = pn.Row(objects=[lo_dfs_available, lo_coll_buttons, lo_coll_interactions])\n",
    "\n",
    "#### Append elements to manage data row\n",
    "dashboard_benchmark.objects[[i.name for i in dashboard_benchmark].index(\"manage_data\")].objects = []\n",
    "for el in [lo_add_datasets, lo_manage_collection]:\n",
    "    dashboard_benchmark.objects[[i.name for i in dashboard_benchmark].index(\"manage_data\")].append(el)\n",
    "\n",
    "#### Management callbacks\n",
    "# upload_collection #Done\n",
    "# load_reference\n",
    "# coll_activatebuttons # Done\n",
    "# coll_downloadjson\n",
    "# coll_editnames\n",
    "# coll_reannotate\n",
    "# coll_runmain #Button change in place\n",
    "# coll_dropmem #Done\n",
    "####\n",
    "\n",
    "lock_collection_change = [\n",
    "    #btn_coll_downloadjson,\n",
    "    #btn_coll_editnames,\n",
    "    #btn_coll_reannotate,\n",
    "    btn_coll_runmain,\n",
    "    btn_coll_dropmem,\n",
    "    i_dfs_available,\n",
    "    i_upload_collection\n",
    "]\n",
    "\n",
    "@pn.depends(i_upload_collection.param.value, watch=True)\n",
    "def upload_collection(file):\n",
    "    \"\"\"\n",
    "    This callback adds the datasets from a .json collection to the global memory object\n",
    "    and updates interface elements accordingly.\n",
    "    \"\"\"\n",
    "    if file == None:\n",
    "        return\n",
    "    # deactivate interface\n",
    "    for el in lock_collection_change:\n",
    "        el.disabled = True\n",
    "    try:\n",
    "        set_status_datamanagement(\"Loading data ...\")\n",
    "        \n",
    "        status = \"\"\n",
    "        json_loaded = json.load(BytesIO(file))\n",
    "        \n",
    "        # Check if experiment names are still free\n",
    "        renamed_exps = []\n",
    "        n_sets = 0\n",
    "        keys = list(json_loaded.keys())\n",
    "        for exp in keys:\n",
    "            if exp in i_dfs_available.options:\n",
    "                renamed_exps.append(exp)\n",
    "                json_loaded[exp+i_upload_collection.filename] = json_loaded.pop(exp)\n",
    "            n_sets += 1\n",
    "        if len(renamed_exps) != 0:\n",
    "            status += f\"\"\"These datasets were already available:<br><br>{\", \".join(renamed_exps)}\n",
    "            <br><br>Please rename them prior to analysis.<br><br><br><br>\"\"\"\n",
    "        \n",
    "        # Load datasets into memory\n",
    "        keys = list(json_loaded.keys())\n",
    "        for exp in keys:\n",
    "            set_status_datamanagement(f\"Loading dataset {exp} ...\")\n",
    "            mem_available_datasets[exp] = json_loaded[exp]\n",
    "        \n",
    "        # Adjust list of available dataset\n",
    "        i_dfs_available.options = i_dfs_available.options + keys\n",
    "        i_dfs_available.value = i_dfs_available.value + keys\n",
    "        resize(lo_dfs_available)\n",
    "        \n",
    "        status += f\"Loaded **{n_sets}** datasets from file **{i_upload_collection.filename}**\"\n",
    "        set_status_datamanagement(status)\n",
    "    except Exception:\n",
    "        set_status_datamanagement(traceback.format_exc())\n",
    "    finally:\n",
    "        # reactivate interface\n",
    "        for el in lock_collection_change:\n",
    "            if type(el) != pn.widgets.button.Button:\n",
    "                el.disabled = False\n",
    "        coll_activatebuttons(i_dfs_available.value)\n",
    "\n",
    "@pn.depends(i_dfs_available.param.value, watch=True)\n",
    "def coll_activatebuttons(v):\n",
    "    \"\"\"\n",
    "    Activate/Deactivate buttons based on selection of available datasets.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(v) == 0:\n",
    "            btn_coll_downloadjson.disabled = True\n",
    "            btn_coll_reannotate.disabled = True\n",
    "            btn_coll_runmain.disabled = True\n",
    "            btn_coll_dropmem.disabled = True\n",
    "        else:\n",
    "            #btn_coll_downloadjson.disabled = False\n",
    "            #btn_coll_reannotate.disabled = False\n",
    "            btn_coll_runmain.disabled = False\n",
    "            btn_coll_dropmem.disabled = False\n",
    "        if len(i_dfs_available.options) == 0:\n",
    "            btn_coll_editnames.disabled = True\n",
    "        else:\n",
    "            #btn_coll_editnames.disabled = False\n",
    "            pass\n",
    "    except Exception:\n",
    "        set_status_datamanagement(traceback.format_exc())\n",
    "\n",
    "\n",
    "def coll_runmain(event):\n",
    "    \"\"\"\n",
    "    Drops selected datasets from collection stored in RAM.\n",
    "    \"\"\"\n",
    "    # deactivate interface\n",
    "    for el in lock_collection_change:\n",
    "        el.disabled = True\n",
    "    try:\n",
    "        if btn_coll_runmain.button_type == \"success\":\n",
    "            set_status_datamanagement(\"Aligning and analysing data ...\")\n",
    "            cache_run_json.value=False\n",
    "            #### Main execution of the comparison\n",
    "            loading_status_comparison.objects = [loading_comparison]\n",
    "            selection = i_dfs_available.value\n",
    "            global i_class_comp\n",
    "            i_class_comp = domaps.SpatialDataSetComparison(ref_exp=selection[0])#, clusters_for_ranking=protein_cluster, organism=i_organism_comparison.value)\n",
    "            i_class_comp.json_dict = {k: mem_available_datasets[k] for k in selection}\n",
    "            set_status_datamanagement(\"Aligning data ...\", append=True)\n",
    "            i_class_comp.read_jsonFile()\n",
    "            set_status_datamanagement(\"Analysing intra-map scatter ...\", append=True)\n",
    "            i_class_comp.calc_biological_precision()\n",
    "            i_class_comp.get_complex_coverage()\n",
    "            update_multi_choice(i_multi_choice, i_clusterwidget_comparison, i_clusters_for_ranking)\n",
    "            set_status_datamanagement(\"Running PCA ...\", append=True)\n",
    "            i_class_comp.perform_pca_comparison()\n",
    "            i_compare_compartment.options = list(set(\n",
    "                i_class_comp.df_01_filtered_combined.index.get_level_values(\"Compartment\")))\n",
    "            #comparison_status.object = \"SVM Processing\"\n",
    "            #i_class_comp.svm_processing()\n",
    "            loading_status_comparison.objects = []\n",
    "            cache_run_json.value=True\n",
    "            set_status_datamanagement(\"Comparison finished!\", append=True)\n",
    "            \n",
    "            #### Switch button mode\n",
    "            btn_coll_runmain.button_type = \"danger\"\n",
    "            btn_coll_runmain.name = \"Reset analysis to make new selection\"\n",
    "            set_status_datamanagement(\n",
    "                \"Next step: Use interface below to evaluate and download benchmark results.\", append=True)\n",
    "        elif btn_coll_runmain.button_type == \"danger\":\n",
    "            set_status_datamanagement(\"Resetting data analysis ...\")\n",
    "            cache_run_json.value=False\n",
    "            \n",
    "            btn_coll_runmain.button_type = \"success\"\n",
    "            btn_coll_runmain.name = \"Align and analyse selected datasets\"\n",
    "            set_status_datamanagement(\"Analysis results have been reset.\")\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    except Exception:\n",
    "        set_status_datamanagement(traceback.format_exc())\n",
    "        cache_run_json.value=False\n",
    "        \n",
    "    finally:\n",
    "        # reactivate interface\n",
    "        if btn_coll_runmain.button_type == \"danger\":\n",
    "            for el in [\n",
    "                btn_coll_runmain,\n",
    "                #btn_coll_editnames\n",
    "            ]:\n",
    "                el.disabled = False\n",
    "        elif btn_coll_runmain.button_type == \"success\":\n",
    "            for el in lock_collection_change:\n",
    "                if type(el) != pn.widgets.button.Button:\n",
    "                    el.disabled = False\n",
    "            coll_activatebuttons(i_dfs_available.value)\n",
    "        else:\n",
    "            for el in lock_collection_change:\n",
    "                if type(el) != pn.widgets.button.Button:\n",
    "                    el.disabled = False\n",
    "            coll_activatebuttons(i_dfs_available.value)\n",
    "            \n",
    "btn_coll_runmain.on_click(coll_runmain)\n",
    "        \n",
    "def coll_dropmem(event):\n",
    "    \"\"\"\n",
    "    Drops selected datasets from collection stored in RAM.\n",
    "    \"\"\"\n",
    "    # deactivate interface\n",
    "    for el in lock_collection_change:\n",
    "        el.disabled = True\n",
    "    try:\n",
    "        set_status_datamanagement(\"Deleting data ...\")\n",
    "        \n",
    "        keys = list(i_dfs_available.value)\n",
    "        for exp in keys:\n",
    "            set_status_datamanagement(f\"Deleting dataset {exp} ...\")\n",
    "            del mem_available_datasets[exp]\n",
    "            \n",
    "        # Adjust list of available dataset\n",
    "        i_dfs_available.options = [el for el in i_dfs_available.options if el not in keys]\n",
    "        i_dfs_available.value = [el for el in i_dfs_available.value if el not in keys]\n",
    "        resize(lo_dfs_available)\n",
    "        i_dfs_available.disabled = True\n",
    "        \n",
    "        set_status_datamanagement(f\"Deleted **{len(keys)}** datasets **{', '.join(keys)}**\")\n",
    "        \n",
    "    except Exception:\n",
    "        set_status_datamanagement(traceback.format_exc())\n",
    "    finally:\n",
    "        # reactivate interface\n",
    "        for el in lock_collection_change:\n",
    "            if type(el) != pn.widgets.button.Button:\n",
    "                el.disabled = False\n",
    "        coll_activatebuttons(i_dfs_available.value)\n",
    "btn_coll_dropmem.on_click(coll_dropmem)\n",
    "\n",
    "#### Benchmark output\n",
    "@pn.depends(cache_run_json.param.value)\n",
    "def display_benchmark_output(run_json):\n",
    "    if run_json:\n",
    "        return pn.Column(\n",
    "            \"## Benchmark results\",\n",
    "            \"Select dataset overlap to plot:\",\n",
    "            pn.Row(i_multi_choice, i_ExpOverview),\n",
    "            comparison_tabs\n",
    "        )\n",
    "    else:\n",
    "        return \"Select data and run analysis.\"\n",
    "\n",
    "#### Append callback output to benchmark output\n",
    "dashboard_benchmark.objects[[i.name for i in dashboard_benchmark].index(\"benchmark_output\")].objects = []\n",
    "for el in [display_benchmark_output]:\n",
    "    dashboard_benchmark.objects[[i.name for i in dashboard_benchmark].index(\"benchmark_output\")].append(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Management tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "i_jsonFile_amendments_intended = pn.widgets.FileInput(name=\"Upload JSON file to be amended\")\n",
    "i_json_ExpSelector = pn.widgets.CrossSelector(name=\"Select experiments, that will be removed from JSON file\", width=1000)\n",
    "cache_uploaded_json_amendment = pn.widgets.Checkbox(value=False)\n",
    "cache_run_json_amendment = pn.widgets.Checkbox(value=False)\n",
    "button_reset = pn.widgets.Button(name=\"Reset\", width=630)\n",
    "download_status = pn.Pane(\"Upload a JSON file first\", width=1000)\n",
    "i_df_ExpComment = pn.widgets.DataFrame()\n",
    "wdgt_json = [button_reset]\n",
    "json_dict_amendments_intended = {}\n",
    "#make a cache, and say, if this hasnt been executed so far, please reset it\n",
    "dict_new_expNames = {}\n",
    "dict_new_comments = {}\n",
    "i_exp_SVM = pn.widgets.Select(name=\"Select experiments as reference\", options=[\"a\", \"b\", \"c\"])\n",
    "button_SVM_analysis = pn.widgets.Button(name=\"Analyse misclassification matrix\", width=50)\n",
    "i_SVM_table = pn.widgets.input.TextAreaInput(name=\"Misclassification matrix from Perseus\", placeholder=\"Copy matrix here...\")\n",
    "cache_uploaded_SVM = pn.widgets.Checkbox(value=False)\n",
    "analysis_status_SVM = pn.Row(pn.Pane(\"No SVM analysis run yet\", width=1000))\n",
    "i_all_or_marker = pn.widgets.Select(name=\"Select type of data for download\", options=[\"Modified AnalysedDataset.json file\", \"0/1 normalized data, all experiments\", \n",
    "                                                                               \"0/1 normalized data, markerset only, all experiments\"], width=300)\n",
    "    \n",
    "@pn.depends(i_jsonFile_amendments_intended.param.value)#cache_run.param.value\n",
    "def open_jsonFile_amendment(jsonFile_amendments):#run\n",
    "    cache_run_json_amendment.value = False\n",
    "    if jsonFile_amendments is None:\n",
    "        cache_uploaded_json_amendment.value = False\n",
    "    else:\n",
    "        dashboard_manageDatasets.objects[2:] = []\n",
    "        #dashboard_manageDatasets.objects = []\n",
    "        dashboard_MissclassificationMatrix.objects = []\n",
    "        dashboard_amendment.objects = []\n",
    "        cache_uploaded_json_amendment.value = False\n",
    "        try:\n",
    "            \n",
    "            json_dict_cache = json.load(BytesIO(i_jsonFile_amendments_intended.value))\n",
    "            if hasattr(json_dict_cache, \"keys\") == False: \n",
    "                    return \"Your json-File does not fulfill the requirements\"\n",
    "            else:\n",
    "                global json_dict_amendments_intended\n",
    "                try:\n",
    "                    json_dict_amendments_intended.update(json_dict_cache)\n",
    "                except Exception:\n",
    "                    json_dict_amendments_intended = json_dict_cache\n",
    "                i_json_ExpSelector.options = list(json_dict_amendments_intended.keys())\n",
    "                cache_uploaded_json_amendment.value = True\n",
    "                for wdgt in wdgt_json:\n",
    "                    wdgt.disabled = False\n",
    "                download_status.object = \"Upload successful! Select experiments now.\"\n",
    "                dashboard_manageDatasets.append(amendment_tabs)\n",
    "                dashboard_manageDatasets.append(button_reset)\n",
    "                dashboard_amendment.append(pn.Column(i_df_ExpComment, download_status))\n",
    "                analysis_status_SVM[0] = pn.Pane(\"Upload successful! Select experiments now.\")\n",
    "                dashboard_MissclassificationMatrix.append(analysis_status_SVM)\n",
    "                return pn.Column(\n",
    "                                 i_json_ExpSelector,\n",
    "                                 i_all_or_marker,           \n",
    "                                 df01_json_download_widget,#pn.Column(pn.widgets.FileDownload(callback=df01_fromJson_download, filename = \"all_01_normalized_data.csv\", width=650)),\n",
    "                                 #button_reset,\n",
    "                                 )\n",
    "        except Exception: \n",
    "            filereading_status_json = traceback.format_exc()\n",
    "            cache_uploaded_json_amendment.value = False\n",
    "            return filereading_status_json\n",
    "\n",
    "    \n",
    "@pn.depends(i_exp_SVM.param.value, watch=True)\n",
    "def update_SVM_Matrix(exp_SVM):\n",
    "    try:\n",
    "        i_SVM_table.value = json_dict_amendments_intended[exp_SVM][\"Misclassification Matrix\"]\n",
    "        \n",
    "    except:\n",
    "        i_SVM_table.value = ''\n",
    "    \n",
    "\n",
    "@pn.depends(i_json_ExpSelector.param.value, watch=True)\n",
    "def update_exp_for_SVM(json_ExpSelector):\n",
    "    if json_ExpSelector == []:\n",
    "        dashboard_MissclassificationMatrix.objects = []\n",
    "        analysis_status_SVM[0] = pn.Pane(\"Select experiments first\")\n",
    "        dashboard_MissclassificationMatrix.append(analysis_status_SVM)\n",
    "    else:\n",
    "        #i_SVM_table.value = \"\"       \n",
    "        dashboard_MissclassificationMatrix.objects = []\n",
    "        i_exp_SVM.options = json_ExpSelector\n",
    "        analysis_status_SVM[0] = pn.Pane(\"Please paste a SVM Matrix first\")\n",
    "        dashboard_MissclassificationMatrix.append(pn.Row(i_exp_SVM, i_SVM_table))\n",
    "        dashboard_MissclassificationMatrix.append(read_SVM_matrix)\n",
    "        dashboard_MissclassificationMatrix.append(analysis_status_SVM)\n",
    "    \n",
    "        \n",
    "@pn.depends(i_SVM_table.param.value)\n",
    "def read_SVM_matrix(SVM_table):   \n",
    "    if SVM_table == \"\":\n",
    "        SVM_reading_status = \"No misclassification matrix is uploaded\"\n",
    "        cache_uploaded_SVM.value = False\n",
    "        analysis_status_SVM[0] = pn.Pane(\"Please paste a SVM Matrix first\")\n",
    "    else:\n",
    "        cache_uploaded_SVM.value = False\n",
    "        try:\n",
    "            try:\n",
    "                df_SVM = pd.DataFrame(json.loads(SVM_table))\n",
    "            except json.JSONDecodeError:\n",
    "                df_SVM = pd.read_table(StringIO(SVM_table), sep=\"\\t\")\n",
    "            json_dict_amendments_intended[i_exp_SVM.value][\"Misclassification Matrix\"] = df_SVM.to_json()\n",
    "            SVM_reading_status = domaps.svm_heatmap(df_SVM)\n",
    "            cache_uploaded_SVM.value = True\n",
    "            #button_SVM_analysis.disabled = False\n",
    "            return pn.Column(#pn.Row(button_SVM_analysis),\n",
    "                             pn.Row(SVM_reading_status, height=600),\n",
    "                            )\n",
    "        except Exception: \n",
    "            SVM_reading_status = \"Paste the SVM matrix from Perseus only!\"\n",
    "            #SVM_reading_status = traceback.format_exc()\n",
    "            cache_uploaded_SVM.value = False\n",
    "            analysis_status_SVM[0] = pn.Pane(traceback.format_exc())    #pn.Pane(\"\")\n",
    "            return SVM_reading_status \n",
    "\n",
    "\n",
    "@pn.depends(cache_run_json_amendment.param.value)\n",
    "def df01_fromJson_download(run):\n",
    "    if i_json_ExpSelector.value == []:\n",
    "        download_status.object = \"No experiments are selected\"\n",
    "        return\n",
    "    else:\n",
    "        df = domaps.reframe_df_01_fromJson_for_Perseus(json_dict_amendments_intended)\n",
    "        df = df.reset_index(\"Compartment\")\n",
    "        df[\"Compartment\"] = [el if el != \"undefined\" else \"\" for el in df.Compartment.values]\n",
    "        df = df.set_index(\"Compartment\", append=True)\n",
    "        sio = StringIO()\n",
    "        df.to_csv(sio)\n",
    "        sio.seek(0)\n",
    "        return sio \n",
    "\n",
    "    \n",
    "@pn.depends(cache_run_json_amendment.param.value)\n",
    "def df01_marker_fromJson_download(run):\n",
    "    if i_json_ExpSelector.value == []:\n",
    "        download_status.object = \"No experiments are selected\"\n",
    "        return\n",
    "    else:\n",
    "        df = domaps.reframe_df_01_fromJson_for_Perseus(json_dict_amendments_intended)\n",
    "        df = df.loc[df.index.get_level_values(\"Compartment\")!= \"undefined\"]\n",
    "        sio = StringIO()\n",
    "        df.to_csv(sio)\n",
    "        sio.seek(0)\n",
    "        return sio \n",
    "    \n",
    "    \n",
    "@pn.depends(cache_run_json_amendment.param.value, i_all_or_marker.param.value)\n",
    "def df01_json_download_widget(run, all_or_marker):\n",
    "    if all_or_marker == \"Modified AnalysedDataset.json file\":\n",
    "        return pn.Column(pn.widgets.FileDownload(callback=json_amendment_download, filename = \"AnalysedDatasets2.0.json\"), width=650) \n",
    "    elif all_or_marker == \"0/1 normalized data, all experiments\":\n",
    "        return pn.Column(pn.widgets.FileDownload(callback=df01_fromJson_download, filename = \"all_01_normalized_data.csv\"), width=650) \n",
    "    else:\n",
    "        return pn.Column(pn.widgets.FileDownload(callback=df01_marker_fromJson_download, filename = \"marker_01_normalized_data.csv\"), width=650)\n",
    "    \n",
    "    \n",
    "def json_amendment_download():\n",
    "    if i_json_ExpSelector.value == []:\n",
    "        download_status.object = \"No experiments are selected\"\n",
    "        return\n",
    "    else:\n",
    "        json_new = json_dict_amendments_intended.copy()\n",
    "        exp_names_del = [elem for elem in i_json_ExpSelector.options if not elem in i_json_ExpSelector.value]        \n",
    "        for key in exp_names_del:\n",
    "            del json_new[key]\n",
    "        checked_exp = set()\n",
    "        redundant_expNames = set(new_Exp for new_Exp in dict_new_expNames.values() if new_Exp in checked_exp or checked_exp.add(new_Exp))\n",
    "        if redundant_expNames != set():\n",
    "            download_status.object = \"Experiments are not allowed to be labelled identically\"\n",
    "            return\n",
    "        else:\n",
    "            for exp_name in json_new:\n",
    "                json_new[exp_name][\"Analysis parameters\"][\"comment\"] = dict_new_comments[exp_name] #dict_new_expNames\n",
    "            json_new = {dict_new_expNames[oldK]: value for oldK, value in json_new.items()}\n",
    "            sio = StringIO()\n",
    "            json.dump(\n",
    "                json_new, \n",
    "                sio, \n",
    "                indent=4, \n",
    "                sort_keys=True\n",
    "            )\n",
    "            sio.seek(0)\n",
    "            download_status.object = \"Download sucessful\"\n",
    "            return sio\n",
    "\n",
    "        \n",
    "def reset_json_amendment(event):\n",
    "    global json_dict_amendments_intended\n",
    "    json_dict_amendments_intended = {}\n",
    "    i_json_ExpSelector.options = []\n",
    "    i_json_ExpSelector.value = []\n",
    "    i_df_ExpComment.value = pd.DataFrame()\n",
    "    for wdgt in wdgt_json:\n",
    "        wdgt.disabled = True\n",
    "    download_status.object = \"Reset sucessful\"\n",
    "button_reset.on_click(reset_json_amendment)\n",
    "\n",
    "\n",
    "@pn.depends(i_json_ExpSelector.param.value, watch=True)\n",
    "def update_renameExp(json_ExpSelector):\n",
    "    dict_ExpComments = {}\n",
    "    for exp_name in json_ExpSelector:\n",
    "        dict_ExpComments[exp_name] = json_dict_amendments_intended[exp_name][\"Analysis parameters\"][\"comment\"]\n",
    "    df_ExpComments = pd.DataFrame(dict_ExpComments.items(), columns=[\"Experiment name - old\", \"Comment\"])#pd.DataFrame.from_dict(dict_ExpComments)\n",
    "    df_ExpComments.insert(0, \"Experiment name - new\", df_ExpComments[\"Experiment name - old\"])\n",
    "    df_ExpComments.set_index(\"Experiment name - old\", inplace=True)\n",
    "    df_ExpComments.replace({\"Experiment name - new\": dict_new_expNames}, inplace=True)\n",
    "    exp_previous = list(dict_new_comments.keys())\n",
    "    for exp in exp_previous:\n",
    "        if exp not in json_ExpSelector:\n",
    "            del dict_new_comments[exp]\n",
    "    df_ExpComments.loc[dict_new_comments.keys(),\"Comment\"] = list(dict_new_comments.values())\n",
    "    i_df_ExpComment.value = df_ExpComments\n",
    "    i_df_ExpComment.height=len(json_ExpSelector)*50\n",
    "    #return i_df_ExpComment\n",
    "\n",
    "@pn.depends(i_df_ExpComment.param.value, watch=True)\n",
    "def update_newExpNames(df_ExpComment):\n",
    "    try:        \n",
    "        global dict_new_expNames \n",
    "        changed_expName = set(list(dict_new_expNames.values())+list(df_ExpComment[\"Experiment name - new\"]))-set(dict_new_expNames.values())\n",
    "        dict_new_expNames = dict(zip(df_ExpComment.index, df_ExpComment[\"Experiment name - new\"]))\n",
    "        global dict_new_comments\n",
    "        dict_new_comments_cache = dict_new_comments.copy()\n",
    "        changed_comment = set(list(dict_new_comments.values())+list(df_ExpComment[\"Comment\"]))-set(dict_new_comments.values())\n",
    "        dict_new_comments = dict(zip(df_ExpComment.index, df_ExpComment[\"Comment\"]))\n",
    "        if changed_expName == set() and changed_comment == set():\n",
    "            tracked_change = \"No changes saved\"\n",
    "        elif changed_expName != set() and changed_comment != set():\n",
    "            tracked_change = \"Upload sucessful\"\n",
    "        elif changed_expName != set():\n",
    "            new_exp = list(changed_expName)[0]\n",
    "            old_exp = list(dict_new_expNames.keys())[list(dict_new_expNames.values()).index(new_exp)]\n",
    "            tracked_change = \"Experiment name was changed from {} to {}\".format(old_exp, new_exp)\n",
    "        else:# changed_comment != set():\n",
    "            new_comment = list(changed_comment)[0]\n",
    "            exp = list(dict_new_comments.keys())[list(dict_new_comments.values()).index(new_comment)]\n",
    "            old_comment = dict_new_comments_cache[exp]\n",
    "            tracked_change = \"Comment of the experiment {} was changed from {} to {}\".format(exp, old_comment, new_comment)\n",
    "        download_status.object = tracked_change\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def save_parameters():\n",
    "    parameters = dict()\n",
    "    parameters[\"multi_choice\"] = i_multi_choice.value\n",
    "    \n",
    "    # PCA plot\n",
    "    parameters[\"xAxis_PCA_comp\"] = i_xAxis_PCA_comp.value\n",
    "    parameters[\"yAxis_PCA_comp\"] = i_yAxis_PCA_comp.value\n",
    "    \n",
    "    # biological precision\n",
    "    parameters[\"clusters_for_ranking\"] = i_clusters_for_ranking.value\n",
    "    parameters[\"reference_map\"] = i_reference_map.value\n",
    "    parameters[\"minn_proteins\"] = i_minn_proteins.value\n",
    "    \n",
    "    # scatter\n",
    "    parameters[\"scatter_metric\"] = i_scatter_metric.value\n",
    "    parameters[\"scatter_consolidation\"] = i_scatter_consolidation.value\n",
    "    \n",
    "    # profile comparison\n",
    "    parameters[\"compare_compartment\"] = i_compare_compartment.value\n",
    "    parameters[\"compare_profile_style\"] = i_compare_profile_style.value\n",
    "    \n",
    "    sio = StringIO()\n",
    "    json.dump(parameters, sio, indent=4)\n",
    "    sio.seek(0)\n",
    "    return sio\n",
    "o_download_parameters = pn.widgets.FileDownload(callback=save_parameters, filename=\"parameters.json\", width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case of loading a json comparison larger than 80 MB\n",
    "#with open(\"G:\\_DIA manuscript\\Figure panes and data\\Figure 1\\Figure1_v2_peptides.json\", \"br\") as file:\n",
    "#    i_jsonFile.value = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case of loading a dingle file larger than 80 MB\n",
    "#i_file.filename = \"filename.txt\"\n",
    "#with open(\"pathtofile.txt\", \"br\") as file:\n",
    "#    i_file.value = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the order of the multi choice widget manually\n",
    "#i_multi_choice.value=[\"21 min\", \"44 min\", \"100 min\", \"DDA\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
