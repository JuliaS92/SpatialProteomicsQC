{
    "about_intro": "Authors: Julia P. Schessner, Vincent Albrecht, Alexandra K. Davies, Pavel Sinitcyn, Georg H.H. Borner<br><br>The code for this tool is available on [github](https://github.com/JuliaS92/SpatialProteomicsQC).<br>If you want to get an overview of the tool please checkout our preprint https://doi.org/10.1101/2021.11.09.467934 or watch the recording of our talk at the [MaxQuant Summer School 2021](https://www.youtube.com/watch?v=dUrOxYHJihc). Please note that the tool has quite significantly changed since then, so some options might no longer be found in the same place as before.<br><br>For any immediate questions please contact schessner@biochem.mpg.de.",
    "home_intro": "Welcome to DOM-QC - the spatial proteomics quality control tool.<br><br>**Notice**<br>The tool is currently still under review and will expand in the future. Please report any errors on [github](https://github.com/JuliaS92/SpatialProteomicsQC/issues). To get an overview of any recent and upcoming changes check the [changelog](https://github.com/JuliaS92/SpatialProteomicsQC/blob/master/NEWS.md), or the [development branch](https://github.com/JuliaS92/SpatialProteomicsQC/tree/development).<br><br>To format and analyse a single experiment (which can include multiple replicate maps), press on the green button below or go to the 'Analysis' tab.<br>There you can upload your search engine output or preprocessed data.<br><br>**IMPORTANT**<br>The webapp only supports upload of files <80 MB. If your input file is too large, you can either trim unnecessary columns (e.g. fasta headers) or run the app locally from [code](https://github.com/valbrecht/SpatialProteomicsQC) to load files directly from your file system.<br><br>Results from a single experiment can be viewed in the 'Analysis' tab.<br>To benchmark multiple experiments, upload multiple input files consecutively through the 'Analysis' tab. They will then be available for comparison in the 'Benchmark' tab.<br><br>To best compare maps measured in separate experiments, it is recommended to use the same sample naming pattern and fraction names for all files (see 'Analysis' tab).",
	"quick_start_guide": "This guide will allow you to quickly test the DOM-QC tool with data generated in this study.\n\n1. Click on the big green button 'Benchmark multiple experiments'.\n2. From the 'Add reference set' drop-down menu (top right corner), select 'HeLa 1x100min libraryDIA'. Click the 'Load' button.\n3. Repeat Step 2., to load the 'HeLa 1x100min DDA' file. \nYou have now loaded two different sets of maps.\n4. Click the big green button 'Align and analyse selected datasets'. This may take a moment - the program will update on progress and tell you when it's finished (bottom right corner).\n5. Scroll down, and select the 'Overview', 'PCA maps', 'Depth and coverage',... tabs to view the different analyses.<br>To configure your own analysis of profiling data, go to the home page and follow the instructions.",
	"upload_instructions": "1. Configure what kind of data you want to upload by selecting input source, acquisition mode and file orientation. Depending on your selection many parameters regarding column naming will be preset accordingly. If these don't match your file just switch the source to custom.\n2. Enter experiment name.\n3. Choose file for upload.<br>**Note**: Be patient - it can take up to 30 seconds to load, **but** the max file size is 80 MB. If you upload a larger file, the tool will simply do nothing. In case the waittime feels too long, check the file size<br>Tip: You can trim a large files by deleting all unnecessary columns (e.g. fasta headers). After successful upload a file preview and further configuration options will be displayed.\n4. Configure column names. Required columns are containing protein group ids, gene names and quantification values.\n5. Configure fraction naming. Based on a regular expression DOMQC will extract the condition (if present), replicate number and fraction from the column names (in pivot format) or sample column (in long format). Use the fraction card to check correct detection of fractions and to edit them.\n6. Adjust data transformations (log transformation and normalization), usually only necessary in custom mode.\n7. Select Annotations - we currently provide manually curated annotations for human, mouse, yeast and arabidopsis. All annotations can also come from a custom file upload. \n7. Adjust data filtering. The options for complex filters depend on the acquisition mode. If you want to e.g. filter for q-value use the simple column filters.\n8. Download the settings to be able to reproduce the analysis later.\n9. Hit the 'Run processing' button and explore your results.", 
	"upload_details": "- Experimental design: you must provide a name pattern as a regular expression (several predefined patterns are provided), with capture groups for replicate, fraction and, optionally, condition. The latter is only used to distinguish same replicate maps of different conditions, but no differential analysis is performed. To compare quality between conditions, you should first create a separate file for each condition.\n- Adjusting fractions: If you want to omit certain fractions from the analysis, e.g. a full proteome that was analysed in the same run, use the fraction card and empty the coresponding name field.",
	"upload_error_messages": "", 
    "analysis_overview_top": "Below are three plots to get an overview of the uploaded data:\n\n1. PCA plot, showing the positioning of the proteins in a 2D/3D projection together with elbow and loading plots.\n2. Sample correlation plots either per fraction, or overall as heatmap.\n3. Histograms of the sample intensities.\n\nIdeally PCA maps of replicate maps should look very similar, correlations between replciate fractions should be > 0.9 and histograms should roughly show the same distribution and height within fractions.\n\n Please use the widgets attached to each plot to customize them as desired.", 
    "analysis_depth_top": "The depth of profiling experiments is often limited by quantifying the same protein across many profile points. Here we distinguish between number of proteins before and after quality filters are applied, respectively. The coverage goes hand in hand with this.\n\nBelow you can see, how these numbers look for each individual fraction.", 
    "analysis_intramap_top": "In this tab you can explore the intramap scatter, as judged by the scatter of profiles within stable protein complexes. We use this as readout, because theoretically proteins in a stable complex should have the same fractionation profile.\n\nFor the selected protein complex you can find:\n\n1. The PCA plot, which is a slice of what is shown in the overview tab.\n2. The profiles of all complex proteins in a selected map.\n3. The distribution of distances in each map and overall as boxplot.\n4. Below these a table shows which proteins were actually quanitfied in which maps in case there was incomplete coverage.\n5. To see which fraction contributes most to the scatter, a boxplot of all distances by fraction and map is shown at the bottom of the page.",
    "mr_top": "In case you have uploaded a comparative experiment (by using a regular expression with the cond group) you can run an analysis of protein transitions here. For each pair of experiments the robust mahalanobis distance of each protein will be calculated, yielding the M-score. The R-score gives information about the reproducibility of these shifts.\n\n1. Define the pairs of maps to compare, either by detecting them automatically or matching them manually.\n2. Select filter for profiles only reproducible within each condition. This will decrease noise affecting the outlier analysis.\n3. Decide the proporiton of data expected to be static and the mode for joining delta profile correlations.\n4. Run a number of iterations of the outlier test to get your results. If you want to run more than 31 interations please download the tool and run it locally.\n5. Use the interactive figure (takes a moment to load) to set your cutoffs for significant outliers and find individual proteins.",
    "benchmark_pca_top": "The PCA plots below show the projections of the loaded datasets onto shared pricnipal components.", 
    "benchmark_depth_top": "The depth of profiling experiments is often limited by quantifying the same protein across many profile points. Here we distinguish between number of proteins before (id) and after quality filters (profile) are applied, respectively. The coverage goes hand in hand with this.\n\nBelow you can see, how the profiled proteins overlap between the experiments, either the ones in at least one replicate or the ones in all replicates. For more than 3 experiments an upsetplot is displayed instead. Beware that 'all maps' can differ in number between experiments.", 
    "benchmark_inter_top": "Reproducibility of profiles has to be assessed differently from preproducibility of single sample quanitifcations. While individual fractions might be well correlated, a single divergent sample distorts the whole profile. Therefore we use distance to an average profile across replicates as a primary measure for reproducibility. Individual sample correlations can be explored below.\n\nIf experiments have vastly different depth it can be useful to include the traces for the full depth, as we only compare based on shared proteins by default. The rugplot can help to judge the tail of the distribution.", 
    "benchmark_intra_top": "In this tab you can explore the intramap scatter, as judged by the scatter of profiles within stable protein complexes. We use this as readout, because theoretically proteins in a stable complex should have the same fractionation profile, therefore if complexes have lower scatter, the experiment should yield more accurate profiles overall.\n\nHere you first see a list of available complexes and how many proteins are quantified across the experiments. You can either select a cutoff for min number of proteins or select the complexes manually.\n\nThe graph shown underneath depicts the median of all complex members' distances to the average complex profile. Only shared proteins are used across experiments. To normalize across complexes all protein-wise distances are divided by the median distance of the respective complex across all experiments. If you wish you can also normalize to a specific experiment (currently requires identical replciate names) to identify differences more quickly.\n\nBelow you can see the PCA plot, which is a slice of what is shown in the PCA tab and the distribution of distances for a selected complex.", 
    "benchmark_SVM_top": "In this tab you can run SVMs on your data or attach a misclassification from externally run SVMs. For external tools we recommend [Perseus](http://coxdocs.org/doku.php?id=perseus:common:download_and_installation), as described [here](https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/cpcb.81#cpcb81-prot-0012). In doing so it is important, to use the same markerset and similar hyperparameters for different experiments as far as possible to achieve a fair comparison. Once you have run the SVMs, copy the misclassification matrices below and the QCtool will calculate precision, recall and F1 scores for each organelle and overall. Alternatively you can use the SVM module build into this tool, which enforces these precautions and implements additional conveniences, like selecting classes, automated training and keeping a hold-out test-set.",
    "benchmark_SVM_internal": "To run SVMs on the selected experiments, follow these steps:\n\n1. Select which classes you want the SVMs to predict and how much of the data you want to set aside for testing. We recommend no less than 10 proteins for training and 4 for testing per class.\n2. Train the hyperparamters C and gamma. The selectable ranges are only the starting search space for the grid search, not a limit. If the training yields parameters at the edge of the searched grid, please change the starting range towards that direction and retrain. The training optimizes for maximum summed accuracy across all incldued experiments.\n3. The best parameters are automatically entered into the fields for C and gamma. There might be other pairs with a very similar accuracy (see downloadble table). Change C and gamma accordingly if you want, e.g. C > 50 is not recommended.\n4. Select probability cutoffs for assigning classes to proteins. The best guess will always be reported either way. Assign a name to your run and run the predictions.", 
    "benchmark_profile_top": "Here you can simply browse the profiles of proteins and organelles. For proteins either enter a protein group identifier or a gene name.", 
    "benchmark_management_top": "In this area of DOMQC you can benchmark multiple experiments against each other. To do so upload datasets here or in the analysis tab and hit the align and analyze button. The alignment will try to maximize overlap between protein groups even if the composition and order protein identifiers do not match exactly.", 
    "coll_status_default": "1. Add datasets for benchmarking using one of the following methods:\nA. Analyse a dataset in the 'Analysis tab' and it will automatically appear in the 'Benchmark' tab.\nB. Upload a stored collection from a .json file. There is an option to download analysed datasets as collection.\nC. Load our stored reference datasets from the dropdown menu.<br>\n2. Tick to select the datasets that you want to compare.\n3. Press the green button 'Align and analyse selected datasets'.\n4. Explore the data using the tabs below.<br><br>Additional notes:<br><ul><li>The datasets selected here only affect the alignment of protein groups and the shared PCA space. The overlap used for benchmarking figures can be adjusted after alignment.</li><li>Press the red button 'Reset analysis to make new selection' to unlock the interface for a new selection of datasets.</li></ul>",
	"benchmark_error_messages": "", 
    "home_single_shortinstructions": "Upload, filter, normalize and quality control your own datasets here. This is required to then run a benchmark against other datasets.",
    "home_benchmark_shortinstructions": "Compare the performance and quality of different experimental datasets, including published reference datasets.",
    "neighborhood_top": "This feature is taken from Martin-Jaular, et al. EMBO Journal 2021. The integration is still ongoing and performance has not been optimized."


}
