{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import param\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import traceback\n",
    "import panel as pn\n",
    "pn.extension(\"plotly\")\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "from bokeh.models.widgets.tables import NumberFormatter\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.findall('(\\D+)',k)\n",
    "#isteEe = [\"02\", \"33\", \"3\"]\n",
    "#items.zfill(2) for items in listeEe]\n",
    "#e.findall('(\\d+)',k)[0].zfill(2)\n",
    "#=[[re.match(name_pattern, col).group(\"frac\")] for col in df_index_LFQ.columns]\n",
    "#isteeeee = list(list(zip(*k))[0])\n",
    "#items.zfill(3) for items in listeeeee]\n",
    "#items.zfill(2) for items in [re.match(name_pattern, col).group(\"frac\")] for col in df_index_LFQ.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stringg= [\"Ratio H/L count MAP1_03K\", \"Ratio H/L variability [%] MAP1_03K\", \"Ratio H/L count MAP1_03K\", \"Ratio H/L variability [%] MAP1_03K\"]\n",
    "#stringg = LFQ intensity Control_Cyt_1\n",
    "#[re.findall(sets_SILAC, stringg) for col in stringg]\n",
    "#k=re.match(\".* (?P<rep>.*)_(?P<frac>.*)\", stringg).group(\"rep\")\n",
    "#k\n",
    "#[[s for s in sets_SILAC if col.startswith(s)][0] for col in stringg]\n",
    "#[re.match(name_pattern_SILAC, col).group(\"frac\")]\n",
    "#[re.match(\"(?P<sets>.*) (?P<rep>.*)_(?P<frac>.*)\", col).group(\"rep\") for col in stringg]\n",
    "#[re.match(\"(?P<sets>.*) (?P<rep>.*)_(?P<frac>.*)\", col).group(\"sets\") for col in stringg]\n",
    "\n",
    "\n",
    "#bool([re.match(name_pattern_SILAC, col) for col in i_class.df_original.columns])\n",
    "#any([[col.startswith(s) for s in sets_SILAC] for col in i_class.df_original.columns])\n",
    "\n",
    "#[items.zfill(3) for items in [\"03K\", \"12K\"]]\n",
    "\n",
    "#bool([re.match(name_pattern_SILAC, col) for col in i_class.df_original.columns])\n",
    "\n",
    "#[re.match(name_pattern_SILAC, col).group(\"sets\") for col in df_index_SILAC.columns]\n",
    "#[col for col in df_index.columns if [re.match(name_pattern_SILAC, col).group(\"\") for s in sets_SILAC]]\n",
    "#len([[s for s in sets_LFQ if re.match(name_pattern_SILAC, col)][0] for col in df_index.columns])\n",
    "\n",
    "\n",
    "#sets_SILAC = [\"Ratio H/L variability [%]\", \"Ratio H/L count\", \"Ratio H/L\"]\n",
    "#\"type_count_silac\": \"([Rr]atio.[Hh]/[Ll].[cC]ount)[ .].*_.*K\",\n",
    "#            \"type_var_silac\": \"([Rr]atio.[Hh]/[Ll].[Vv]ariability....)[ .].*_.*K\",\n",
    "#            \"type_ratio_silac\": \"([rR]atio.[Hh]/[Ll])[ .](?![cC]ount|[Vv]ariability).*_.*K\",\n",
    "\n",
    "#negative lookaheadf\n",
    "#if len re.findall\n",
    "#([[re.match(s, col) for s in sets_SILAC] for col in test_liast])\n",
    "\n",
    "\n",
    "#i_acquisition = pn.widgets.Select(options=[\"LFQ\",\"SILAC\"])\n",
    "#i_class.acquisition= i_acquisition.value\n",
    "#i_sets = pn.widgets.Select(options=acquisition_set_dic[i_acquisition.value])\n",
    "#\n",
    "#@pn.depends(i_acquisition.param.value, watch=True)\n",
    "#def update_sets(acquisition):\n",
    "#    acquistion = acquisition_set_dic[acquisition]\n",
    "#    i_sets.options = acquistion\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDataSet:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Import of the raw file of interest. Dataframe will be generated, which contains only the data of desired\n",
    "        column names, specified by the dictionary entry regex[\"col_shortened\"]\n",
    "\n",
    "        Dictionaries are created, that ate used for filtering and plotting, respectively.\n",
    "\n",
    "        Args:\n",
    "            filename: raw file obtained by the LFQ/SILAC approach (Protein Groups Files), processed by MaxQuant\n",
    "\n",
    "        Returns:\n",
    "            df_original: shortened data frame, contains only the information, which was determined due to\n",
    "            the values of the key \"col_shortened\"\n",
    "        \"\"\"\n",
    "        # df_original contains all information of the raw file; tab separated file is imported,\n",
    "        # without considering comments, marked with #\n",
    "\n",
    "        #self.filename = \"LFQ_proteinGroups.txt\" if \"filename\" not in kwargs.keys() else kwargs[\"filename\"]\n",
    "        #self.filename = \"proteinGroupsCOVID.txt\" if \"filename\" not in kwargs.keys() else kwargs[\"filename\"]\n",
    "        #self.filename = \"proteinGroups_LFQ_Deep_3_Maps.txt\" if \"filename\" not in kwargs.keys() else kwargs[\"filename\"]\n",
    "        self.filename = \"6_deep_maps.txt\" if \"filename\" not in kwargs.keys() else kwargs[\"filename\"]\n",
    "        \n",
    "        self.map_of_interest = \"MAP1\" if \"map_of_interest\" not in kwargs.keys() else kwargs[\"map_of_interest\"]\n",
    "        self.cluster_of_interest = \"Proteasome\" if \"cluster_of_interest\" not in kwargs.keys() else kwargs[\n",
    "            \"cluster_of_interest\"]\n",
    "\n",
    "        self.summed_MSMS_counts = 2 if \"summed_MSMS_counts\" not in kwargs.keys() else kwargs[\"summed_MSMS_counts\"]\n",
    "        self.consecutive_LFQ_I = 4 if \"consecutive_LFQ_I\" not in kwargs.keys() else kwargs[\"consecutive_LFQ_I\"]\n",
    "\n",
    "        # self.lfq_filter_param = {\"summed MS/MS counts\": 2, \"consecutive LFQ_I\": 4}\n",
    "\n",
    "        self.regex = {\n",
    "            \"imported_columns\": \"^[Rr]atio H/L (?!normalized|type|is.*).+|id$|[Mm][Ss].*[cC]ount.+$|[Ll][Ff][Qq].*|.*[nN]ames.*|.*[Pp][rR].*[Ii][Dd]s.*|[Pp]otential.[cC]ontaminant|[Oo]nly.[iI]dentified.[bB]y.[sS]ite|[Rr]everse|[Ss]core|[Qq]-[Vv]alue\",\n",
    "#            \"index_col_silac\": \"[Pp]rotein.[Ii][Dd]s|[Mm]ajority.[Pp]rotein.[Ii][Dd]s|[Pp]rotein.[Nn]ames|[Gg]ene.[Nn]ames|[Ii][Dd]|[Ss]core|[Qq]-[Vv]alue\",\n",
    "#            \"index_col_lfq\": \".*[Pp][rR].*[Ii][Dd]s.*|.*[nN]ames.*|[Ii][Dd]|[Ss]core|[Qq]-[Vv]alue|MS/MS.count$\",\n",
    "\n",
    "#            \"type_count_silac\": \"([Rr]atio.[Hh]/[Ll].[cC]ount)[ .].*_.*K\",\n",
    "#            \"type_var_silac\": \"([Rr]atio.[Hh]/[Ll].[Vv]ariability....)[ .].*_.*K\",\n",
    "#            \"type_ratio_silac\": \"([rR]atio.[Hh]/[Ll])[ .](?![cC]ount|[Vv]ariability).*_.*K\",\n",
    "#\n",
    "#            \"type_count_lfq\": \"([Rr]atio.[Hh]/[Ll].[cC]ount)[ .].*_.*K\",\n",
    "#            \"type_var_lfq\": \"([Rr]atio.[Hh]/[Ll].[Vv]ariability....)[ .].*_.*K\",\n",
    "#            \"type_ratio_silac\": \"([rR]atio.[Hh]/[Ll])[ .](?![cC]ount|[Vv]ariability).*_.*K\",\n",
    "#\n",
    "#            \"type_msms_lfq\": \"([Mm][Ss]/[Mm][Ss].[cC]ount)[ .].*_.*K\",\n",
    "#            \"type_intensity_lfq\": \"([Ll][Ff][Qq].[Ii]ntensity)[ .].*_.*K\",\n",
    "\n",
    "            # \"type_lfq\": \"(.*[nNTt]{1}[yYtT]{1})[ .].*_\\d+[Kk]$\",\n",
    "\n",
    "            #\"lfq_nan\": \"[Ll][Ff][Qq].*\",\n",
    "\n",
    "            #\"contaminants\": \"[Pp]otential.[cC]ontaminant\",\n",
    "            #\"sites\": \"[Oo]nly.[iI]dentified.[bB]y.[sS]ite\",\n",
    "            #\"reverse\": \"[Rr]everse\"\n",
    "        }\n",
    "        \n",
    "        #self.acquisition = \"SILAC\" if \"acquisition\" not in kwargs.keys() else kwargs[\"acquisition\"]\n",
    "        self.acquisition = \"LFQ\" if \"acquisition\" not in kwargs.keys() else kwargs[\"acquisition\"]\n",
    "        \n",
    "        self.acquisition_set_dict = {\n",
    "        'LFQ': [\"[Ll][Ff][Qq].[Ii]ntensity\", \"[Mm][Ss]/[Mm][Ss].[cC]ount\", \"[Ii]ntensity\"],\n",
    "        'SILAC'  : [ \"[Rr]atio.[Hh]/[Ll](?!.[Vv]aria|.[Cc]ount)\",\"[Rr]atio.[Hh]/[Ll].[Vv]ariability.\\[%\\]\", \"[Rr]atio.[Hh]/[Ll].[cC]ount\"]\n",
    "        }\n",
    "        \n",
    "        self.name_pattern = \".* (?P<cond>.*)_(?P<rep>.*)_(?P<frac>.*)\" if \"name_pattern\" not in kwargs.keys() else kwargs[\"name_pattern\"]\n",
    "        #name_pattern_LFQ = \".* (?P<cond>.*)_(?P<rep>.*)_(?P<frac>.*)\"\n",
    "        #name_pattern_SILAC = \".* (?P<rep>.*)_(?P<frac>.*)\"\n",
    "        #name_pattern_SILAC = \"(?P<sets>.*) (?P<rep>.*)_(?P<frac>.*)\"\n",
    "        \n",
    "        self.fraction_dict = {\"1K\": \"01K\",\"3K\": \"03K\", \"6K\": \"06K\", \"12K\": \"12K\", \"24K\": \"24K\", \"80K\": \"80K\", \"01K\": \"01K\",\"03K\": \"03K\", \"06K\": \"06K\", \"012K\": \"12K\", \"024K\": \"24K\", \"080K\": \"80K\", \"Cyt\": \"Cyt\", \"Mem\": \"Mem\", \"Nuc\": \"Nuc\", \"Prot\": \"Prot\", \"cyt\": \"Cyt\"}\n",
    "        \n",
    "        self.analysed_datasets_dict = {}\n",
    "        self.analysis_summary_dict = {}\n",
    "        self.shape_dict = {}  \n",
    "        self.expname = \"Protein_Groups\" if \"expname\" not in kwargs.keys() else kwargs[\"expname\"]\n",
    "            #msms_counts:\n",
    "        \n",
    "        \n",
    "    def data_reading(self):\n",
    "        \"\"\"Data import.\n",
    "\n",
    "        Args:\n",
    "            filename: stored as attribute\n",
    "\n",
    "        Returns:\n",
    "            df_orginal: raw, unprocessed dataframe, single level column index\n",
    "        \"\"\"\n",
    "\n",
    "        self.df_original = pd.read_csv(self.filename, sep=\"\\t\", comment=\"#\",\n",
    "                                       usecols=lambda x: bool(re.match(self.regex[\"imported_columns\"], x)))\n",
    "\n",
    "        return self.df_original\n",
    "    \n",
    "    def processingdf(self):\n",
    "        \"\"\"Analysis of the SILAC/LFQ data will be performed.\n",
    "\n",
    "        The dataframe will be filtered, normalized and converted into a dataframe, characterized by a flat column index,\n",
    "        which can be used for plotting\n",
    "\n",
    "        Args:\n",
    "            acquisition mode: \"SILAC\" or \"LFQ\", which is referring to the acquisition method\n",
    "\n",
    "        Returns:\n",
    "            A dataframe, in which \"Fraction\" and \"Map\" are stacked, containing \"normalized profile\" as column,\n",
    "            additionally \"Ratio H/L count\", \"Ratio H/L variability [%]\" is found for SILAC data and \"MS/MS count\"\n",
    "            for LFQ data; represented as a flat column index\n",
    "        \"\"\"\n",
    "    \n",
    "        def indexingdf(df_original, acquisition_set_dict, acquisition, fraction_dict, name_pattern, shape_dict):\n",
    "            # deep copy of the dataframe\n",
    "            df_original = self.df_original.copy()\n",
    "            df_i = df_original.set_index([col for col in df_original.columns if any([re.match(s, col) for s in self.acquisition_set_dict[self.acquisition]]) == False])\n",
    "    \n",
    "            # multindex will be generated, by isolating the information about the Map, Fraction and Type from each\n",
    "            # individual column name\n",
    "            # names=[\"Set\", \"Map\", \"Fraction\"] defines the label of the multiindex\n",
    "            multiindex = pd.MultiIndex.from_arrays(\n",
    "                    arrays=[\n",
    "                        [item for sublist in [[re.findall(s, col)[0] for s in self.acquisition_set_dict[self.acquisition] if re.match(s,col)] for col in df_i.columns] for item in sublist],\n",
    "            \n",
    "                        [re.match(self.name_pattern, col).group(\"rep\") for col in df_i.columns] \n",
    "                        if not \"<cond>\" in self.name_pattern \n",
    "                        else [\"_\".join(re.match(self.name_pattern, col).group(\"cond\", \"rep\")) for col in df_i.columns],\n",
    "                        \n",
    "                        [self.fraction_dict[re.match(self.name_pattern, col).group(\"frac\")] for col in df_i.columns],\n",
    "                    ],\n",
    "                    names=[\"Set\", \"Map\", \"Fraction\"]\n",
    "                        )\n",
    "            df_i.columns = multiindex\n",
    "            df_i.sort_index(1, inplace=True)\n",
    "            \n",
    "            self.shape_dict[\"Shape before categorical filtering\"]=df_i.shape\n",
    "            \n",
    "            df_index = df_i.xs(\n",
    "                    np.nan, 0, \"Reverse\").xs(\n",
    "                    np.nan, 0, \"Potential contaminant\").xs(\n",
    "                    np.nan, 0, \"Only identified by site\")\n",
    "            \n",
    "            self.shape_dict[\"Shape after categorical filtering\"]=df_i.shape\n",
    "    \n",
    "            return df_index   \n",
    "    \n",
    "\n",
    "        def stringency_silac(df_index):\n",
    "            \"\"\"The multiindex dataframe is subjected to stringency filtering. Only Proteins with complete profiles are\n",
    "            considered (a set of f.e. 5 SILAC ratios in case you have 5 fractions / any proteins with missing values\n",
    "            were rejected). Proteins were retained with 3 or more quantifications in each subfraction (=count). Furthermore,\n",
    "            proteins with only 2 quantification events in one or more subfraction were retained, if their ratio\n",
    "            variability for ratios obtained with 2 quantification events was below 30% (=var).\n",
    "            SILAC ratios were linearly normalized by division through the fraction median. Subsequently normalization\n",
    "            to SILAC loading was performed.\n",
    "\n",
    "            Args:\n",
    "                df_index: multiindex dataframe, which contains 3 level labels: MAP, Fraction, Type\n",
    "\n",
    "            Returns:\n",
    "                df_stringency_mapfracstacked: dataframe, in which \"MAP\" and \"Fraction\" are stacked;\n",
    "                the columns \"Ratio H/L count\", \"Ratio H/L variability [%]\", and \"Ratio H/L\" stored as single level indices\n",
    "            \"\"\"\n",
    "\n",
    "            # Fraction and Map will be stacked\n",
    "            df_stack = df_index.stack([\"Fraction\", 'Map'])\n",
    "\n",
    "            len_fractions = len(df_stack.index.get_level_values(\"Fraction\").unique())\n",
    "\n",
    "            # filtering for sufficient number of quantifications (count in 'Ratio H/L count'), taken\n",
    "            # variability (var in Ratio H/L variability [%]) into account\n",
    "            # zip: allows direct comparison of count and var\n",
    "            # only if the filtering parameters are fulfilled the data will be introduced into df_countvarfiltered_stacked\n",
    "            df_countvarfiltered_stacked = df_stack.loc[[count >= 3 or (count >= 2 and var < 30) for var, count in\n",
    "                                                        zip(df_stack[\"Ratio H/L variability [%]\"],\n",
    "                                                            df_stack['Ratio H/L count'])]]\n",
    "            \n",
    "            self.shape_dict[\"Shape after Ratio H/L count (>= 3)/var (count>=2, var<30) filtering\"]=df_countvarfiltered_stacked.shape\n",
    "\n",
    "            # \"Ratio H/L\":normalization to SILAC loading, each individual experiment (FractionXMap) will be divided by its median\n",
    "            # np.median([...]): only entries, that are not NANs are considered\n",
    "            df_normsilac_stacked = df_countvarfiltered_stacked[\"Ratio H/L\"].unstack([\"Fraction\", \"Map\"]).apply(\n",
    "                lambda x: x / np.median([el for el in x if not np.isnan(el)]), axis=0).stack([\"Map\", \"Fraction\"])\n",
    "\n",
    "            df_stringency_mapfracstacked = df_countvarfiltered_stacked[[\"Ratio H/L count\",\n",
    "                                                                    \"Ratio H/L variability [%]\"]].join(\n",
    "                pd.DataFrame(df_normsilac_stacked, columns=[\"Ratio H/L\"]))\n",
    "\n",
    "            # dataframe is grouped (Map, id), that allows the filtering for complete profiles\n",
    "            df_stringency_mapfracstacked = df_stringency_mapfracstacked.groupby([\"Map\", \"id\"]).filter(\n",
    "                lambda x: len(x) >= len_fractions)\n",
    "            \n",
    "            self.shape_dict[\"Shape after filtering for complete profiles\"]=df_stringency_mapfracstacked.shape\n",
    "            \n",
    "            # Ratio H/L is converted into Ratio L/H\n",
    "            df_stringency_mapfracstacked[\"Ratio H/L\"] = df_stringency_mapfracstacked[\"Ratio H/L\"].transform(lambda x: 1 / x)\n",
    "\n",
    "\n",
    "            return df_stringency_mapfracstacked\n",
    "\n",
    "\n",
    "        def normalization_01_silac(df_stringency_mapfracstacked):\n",
    "            \"\"\"The multiindex dataframe, that was subjected to stringency filtering, is 0-1 normalized (\"Ratio H/L\").\n",
    "\n",
    "            Args:\n",
    "                df_stringency_mapfracstacked: dataframe, in which \"MAP\" and \"Fraction\" are stacked;\n",
    "                the columns \"Ratio H/L count\", \"Ratio H/L variability [%]\", and \"Ratio H/L\" stored as single level indices\n",
    "\n",
    "            Returns:\n",
    "                df_01_stacked: dataframe, in which \"MAP\" and \"Fraction\" are stacked; data in the column\n",
    "                \"Ratio H/L\" is 0-1 normalized and renamed to \"normalized profile\"; the columns \"Ratio H/L count\",\n",
    "                \"Ratio H/L variability [%]\", and \"normalized profile\" stored as single level indices;\n",
    "                plotting is possible now\n",
    "            \"\"\"\n",
    "\n",
    "            df_01norm_unstacked = df_stringency_mapfracstacked[\"Ratio H/L\"].unstack(\"Fraction\")\n",
    "\n",
    "            # 0:1 normalization of Ratio L/H\n",
    "            df_01norm_unstacked = df_01norm_unstacked.div(df_01norm_unstacked.sum(axis=1), axis=0)\n",
    "\n",
    "            df_01_stacked = df_stringency_mapfracstacked[[\"Ratio H/L count\", \"Ratio H/L variability [%]\"]].join(pd.DataFrame\n",
    "                (\n",
    "                df_01norm_unstacked.stack(\n",
    "                    \"Fraction\"),\n",
    "                columns=[\n",
    "                    \"Ratio H/L\"]))\n",
    "\n",
    "            # \"Ratio H/L\" will be renamed to \"normalized profile\"\n",
    "            df_01_stacked.columns = [col if col != \"Ratio H/L\" else \"normalized profile\" for col in\n",
    "                                     df_01_stacked.columns]\n",
    "\n",
    "            return df_01_stacked\n",
    "\n",
    "\n",
    "        def logarithmization_silac(df_stringency_mapfracstacked):\n",
    "            \"\"\"The multiindex dataframe, that was subjected to stringency filtering, is logarithmized (\"Ratio H/L\").\n",
    "\n",
    "            Args:\n",
    "                df_stringency_mapfracstacked: dataframe, in which \"MAP\" and \"Fraction\" are stacked;\n",
    "                the columns \"Ratio H/L count\", \"Ratio H/L variability [%]\", and \"Ratio H/L\" stored as single level indices\n",
    "\n",
    "            Returns:\n",
    "                df_log_stacked: dataframe, in which \"MAP\" and \"Fraction\" are stacked; data in the column\n",
    "                \"log profile\" originates from logarithmized \"Ratio H/L\" data; the columns \"Ratio H/L count\",\n",
    "                \"Ratio H/L variability [%]\" and  \"log profile\" are stored as single level indices; PCA is possible now\n",
    "\n",
    "            \"\"\"\n",
    "            # logarithmizing, basis of 2\n",
    "            df_lognorm_ratio_stacked = df_stringency_mapfracstacked[\"Ratio H/L\"].transform(np.log2)\n",
    "            df_log_stacked = df_stringency_mapfracstacked[[\"Ratio H/L count\", \"Ratio H/L variability [%]\"]].join(\n",
    "                pd.DataFrame\n",
    "                (df_lognorm_ratio_stacked, columns=[\"Ratio H/L\"]))\n",
    "\n",
    "            # \"Ratio H/L\" will be renamed to \"log profile\"\n",
    "            df_log_stacked.columns = [col if col != \"Ratio H/L\" else \"log profile\" for col in df_log_stacked.columns]\n",
    "\n",
    "            return df_log_stacked\n",
    "\n",
    "        \n",
    "        def stringency_lfq(df_index):\n",
    "            \"\"\"The multiindex dataframe is subjected to stringency filtering. Only Proteins which were identified with\n",
    "            at least [4] consecutive data points regarding the \"LFQ intensity\", and if summed MS/MS counts >= n(fractions)*[2]\n",
    "            (LFQ5: min 10 and LFQ6: min 12, respectively; coverage filtering) were included.\n",
    "\n",
    "            Args:\n",
    "                df_index: multiindex dataframe, which contains 3 level labels: MAP, Fraction, Typ\n",
    "\n",
    "            Returns:\n",
    "                df_stringency_mapfracstacked: dataframe, in which \"Map\" and \"Fraction\" is stacked;\n",
    "                \"LFQ intensity\" and \"MS/MS count\" define a single-level column index\n",
    "                \"\"\"\n",
    "\n",
    "            # retrieve number of fractions that are present in the dataset\n",
    "            df_fractionnumber_stacked = df_index.copy().stack(\"Fraction\")\n",
    "            number_fractions = len(df_fractionnumber_stacked.index.get_level_values(\"Fraction\").unique())\n",
    "\n",
    "            df_index = df_index.stack(\"Map\")\n",
    "\n",
    "            # sorting the level 0, in order to have LFQ intensity -\tMS/MS count instead of continuous alternation\n",
    "            df_index.sort_index(axis=1, level=0, inplace=True)\n",
    "\n",
    "            # \"MS/MS count\"-column: take the sum over the fractions;\n",
    "            # if the sum is larger than n[fraction]*2, it will be stored in the new dataframe\n",
    "            df_mscount_mapstacked = df_index.loc[df_index[('MS/MS count')].apply(np.sum, axis=1) >= (\n",
    "                    number_fractions * self.summed_MSMS_counts)]\n",
    "\n",
    "            self.shape_dict[\"Shape after MS/MS value filtering\"]=df_mscount_mapstacked.shape\n",
    "            \n",
    "            df_stringency_mapfracstacked = df_mscount_mapstacked.copy()\n",
    "\n",
    "            # series no dataframe is generated; if there are at least i.e. 4 consecutive non-NANs, data will be retained\n",
    "            df_stringency_mapfracstacked = df_stringency_mapfracstacked.loc[\n",
    "                df_stringency_mapfracstacked[(\"LFQ intensity\")].apply(lambda x: any(\n",
    "                    np.invert(np.isnan(x)).rolling(window=self.consecutive_LFQ_I).sum() >=\n",
    "                    self.consecutive_LFQ_I), axis=1)]\n",
    "            \n",
    "            self.shape_dict[\"Shape after consecutive value filtering\"]=df_stringency_mapfracstacked.shape\n",
    "\n",
    "            df_stringency_mapfracstacked = df_stringency_mapfracstacked.copy().stack(\"Fraction\")\n",
    "\n",
    "            return df_stringency_mapfracstacked\n",
    "\n",
    "\n",
    "        def normalization_01_lfq(df_stringency_mapfracstacked):\n",
    "            \"\"\"The multiindex dataframe, that was subjected to stringency filtering, is 0-1 normalized (\"LFQ intensity\").\n",
    "\n",
    "            Args:\n",
    "                df_stringency_mapfracstacked: dataframe, in which \"Map\" and \"Fraction\" is stacked;\n",
    "                \"LFQ intensity\" and \"MS/MS count\" define a single-level column index\n",
    "\n",
    "\n",
    "            Returns:\n",
    "                df_01_stacked: dataframe, in which \"MAP\" and \"Fraction\" are stacked; data in the column\n",
    "                \"LFQ intensity\" is 0-1 normalized and renamed to \"normalized profile\";\n",
    "                the columns \"\"normalized profile\"\" and \"MS/MS count\" are stored as\n",
    "                single level indices; plotting is possible now\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            df_01norm_mapstacked = df_stringency_mapfracstacked[\"LFQ intensity\"].unstack(\"Fraction\")\n",
    "\n",
    "            # 0:1 normalization of Ratio L/H\n",
    "            df_01norm_unstacked = df_01norm_mapstacked.div(df_01norm_mapstacked.sum(axis=1), axis=0)\n",
    "\n",
    "            df_01_stacked = df_stringency_mapfracstacked[[\"MS/MS count\"]].join(pd.DataFrame(df_01norm_unstacked.stack(\n",
    "                   \"Fraction\"),columns=[\"LFQ intensity\"]))\n",
    "\n",
    "            # rename columns: \"LFQ intensity\" into \"normalized profile\"\n",
    "            df_01_stacked.columns = [col if col != \"LFQ intensity\" else \"normalized profile\" for col in\n",
    "                                     df_01_stacked.columns]\n",
    "            df_01_stacked = df_01_stacked.sort_index()\n",
    "            return df_01_stacked\n",
    "\n",
    "\n",
    "        def logarithmization_lfq(df_stringency_mapfracstacked):\n",
    "            \"\"\"The multiindex dataframe, that was subjected to stringency filtering, is logarithmized (\"LFQ intensity\").\n",
    "\n",
    "            Args:\n",
    "                df_stringency_mapfracstacked: dataframe, in which \"Map\" and \"Fraction\" is stacked;\n",
    "                \"LFQ intensity\" and \"MS/MS count\" define a single-level column index\n",
    "\n",
    "            Returns:\n",
    "                df_log_stacked: dataframe, in which \"MAP\" and \"Fraction\" are stacked; data in the column \"log profile\"\n",
    "                originates from logarithmized  \"LFQ intensity\"; the columns \"log profile\" and \"MS/MS count\" are\n",
    "                stored as single level indices; PCA is possible now\n",
    "            \"\"\"\n",
    "\n",
    "            df_lognorm_ratio_stacked = df_stringency_mapfracstacked[\"LFQ intensity\"].transform(np.log2)\n",
    "            #df_log_stacked = df_stringency_mapfracstacked.copy()\n",
    "            #df_log_stacked[\"LFQ intensity\"] = df_lognorm_mapstacked\n",
    "            #df_log_stacked = df_log_stacked.fillna(0).stack(\"Fraction\")\n",
    "\n",
    "            df_log_stacked = df_stringency_mapfracstacked[[\"MS/MS count\"]].join(pd.DataFrame\n",
    "                (df_lognorm_ratio_stacked, columns=[\"LFQ intensity\"]))\n",
    "\n",
    "            # \"Ratio H/L\" will be renamed to \"log profile\"\n",
    "            df_log_stacked.columns = [col if col != \"LFQ intensity\" else \"log profile\" for col in df_log_stacked.columns]\n",
    "\n",
    "            return df_log_stacked\n",
    "\n",
    "\n",
    "        if self.acquisition == \"SILAC\":\n",
    "            df_index = indexingdf(self.df_original, self.acquisition_set_dict, self.acquisition, self.fraction_dict, self.name_pattern, self.shape_dict)\n",
    "            df_stringency_mapfracstacked = stringency_silac(df_index)\n",
    "            df_01_stacked = normalization_01_silac(df_stringency_mapfracstacked)\n",
    "            df_log_stacked = logarithmization_silac(df_stringency_mapfracstacked)\n",
    "            self.df_log_stacked = df_log_stacked\n",
    "            self.df_01_stacked = df_01_stacked\n",
    "            fractions = df_01_stacked.index.get_level_values(\"Fraction\").unique()\n",
    "            self.fractions = fractions\n",
    "            map_names = self.df_01_stacked.index.get_level_values(\"Map\").unique()\n",
    "            self.map_names = map_names\n",
    "            \n",
    "            self.analysis_summary_dict[\"changes in Shape after filtering\"] = self.shape_dict.copy() \n",
    "            self.analysis_parameters = {\"acquisition\" : self.acquisition, \"filename\" : self.filename}\n",
    "            self.analysis_summary_dict[\"Analysis parameters\"] = self.analysis_parameters.copy() \n",
    "            self.analysed_datasets_dict[self.expname] = self.analysis_summary_dict.copy() \n",
    "\n",
    "            self.analysis_summary_dict.clear()\n",
    "            self.shape_dict.clear()\n",
    "            self.analysis_parameters.clear() \n",
    "            return self.analysed_datasets_dict\n",
    "\n",
    "\n",
    "        elif self.acquisition == \"LFQ\":\n",
    "            df_index = indexingdf(self.df_original, self.acquisition_set_dict, self.acquisition, self.fraction_dict, self.name_pattern, self.shape_dict)\n",
    "            df_stringency_mapfracstacked = stringency_lfq(df_index)\n",
    "            df_01_stacked = normalization_01_lfq(df_stringency_mapfracstacked)\n",
    "            df_log_stacked = logarithmization_lfq(df_stringency_mapfracstacked)\n",
    "            self.df_log_stacked = df_log_stacked\n",
    "            self.df_01_stacked = df_01_stacked\n",
    "            fractions = df_01_stacked.index.get_level_values(\"Fraction\").unique()\n",
    "            self.fractions = fractions\n",
    "            map_names = self.df_01_stacked.index.get_level_values(\"Map\").unique()\n",
    "            self.map_names = map_names\n",
    "            \n",
    "            self.analysis_summary_dict[\"changes in Shape after filtering\"] = self.shape_dict.copy() \n",
    "            self.analysis_parameters = {\"acquisition\" : self.acquisition, \"filename\" : self.filename}\n",
    "            self.analysis_summary_dict[\"Analysis parameters\"] = self.analysis_parameters.copy() \n",
    "            self.analysed_datasets_dict[self.expname] = self.analysis_summary_dict.copy() \n",
    "            \n",
    "            self.analysis_summary_dict.clear()\n",
    "            self.shape_dict.clear()\n",
    "            #self.analysis_parameters.clear() \n",
    "            return self.analysed_datasets_dict\n",
    "\n",
    "\n",
    "        else:\n",
    "            return \"I don't know this\"    \n",
    "        \n",
    "        #df_index = indexingdf(self.df_original)\n",
    "        #return df_index    \n",
    "    \n",
    "    #list_drop_col = [column for column in df_index.columns if not column.startswith(\"Ratio \")]\n",
    "    #list_endcount = [column for column in df_index.columns if column.endswith(\"count\")]\n",
    "    #list_endpct = [column for column in df_index.columns if column.endswith(\"[%]\")]\n",
    "    #\n",
    "    #list_drop_col.extend(list_endcount)\n",
    "    #list_drop_col.extend(list_endpct)\n",
    "    #\n",
    "    #df_index = df_index.drop(list_drop_col, axis=1)\n",
    "            \n",
    "            # \"LFQ intensity\"-values: converting 0 into NAN\n",
    "            # iteration through the column names, and searches for column names (LFQ intensity, deposited as regular\n",
    "            # expression in the dictionary entry regex[\"lfq_nan\"]\n",
    "            #df_index[[col for col in df_index.columns if re.match(regex[\"lfq_nan\"], col)]] = \\\n",
    "            #    df_index[[col for col in df_index.columns if re.match(regex[\"lfq_nan\"], col)]].replace(0, np.nan)\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_expname = pn.widgets.TextInput(name='Experiment Name', placeholder='Enter a string here...')\n",
    "i_acquisition = pn.widgets.Select(name='Acquisition', options=[\"LFQ\",\"SILAC\"])\n",
    "i_file = pn.widgets.Select(name='File',options=[\"6_deep_maps.txt\",\"LFQ_proteinGroups.txt\",\"proteinGroupsCOVID.txt\", \n",
    "                                              \"proteinGroups_LFQ_Deep_3_Maps.txt\"])\n",
    "i_name_pattern = pn.widgets.Select(name='Name patteren',options=[\".* (?P<rep>.*_.*)_(?P<frac>.*)\",\".* (?P<rep>.*)_(?P<frac>.*)\", \".* (?P<cond>.*)_(?P<frac>.*)_(?P<rep>.*)\"])\n",
    "\n",
    "regex_pattern = {\n",
    "    \".* (?P<rep>.*)_(?P<frac>.*)\" : [\"MAP1_03K\",\"MAP3_03K\"],\n",
    "    \".* (?P<rep>.*_.*)_(?P<frac>.*)\" : [\"EGF_rep1_06K\",\"EGF_rep3_06K\"],\n",
    "    \".* (?P<cond>.*)_(?P<frac>.*)_(?P<rep>.*)\" : [\"Control_Mem_1\", \"Control_Cyt_1\"]\n",
    "    }\n",
    "\n",
    "pattern_examples = pn.widgets.Select(name = \"Examples\", options=regex_pattern[i_name_pattern.value])\n",
    "\n",
    "@pn.depends(i_name_pattern.param.value, watch=True)\n",
    "def update_sets(name_pattern):\n",
    "    example_for_name_pattern = regex_pattern[name_pattern]\n",
    "    pattern_examples.options = example_for_name_pattern\n",
    "\n",
    "#i_name_pattern = pn.widgets.Select(options=[\".* (?P<cond>.*)_(?P<rep>.*)_(?P<frac>.*)\",\".* (?P<rep>.*)_(?P<frac>.*)\"])\n",
    "\n",
    "pn.Column(pn.Row(i_acquisition, i_file, i_expname), pn.Row(i_name_pattern, pattern_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_check= [i_file.value, i_acquisition.value, i_name_pattern.value, i_expname.value]\n",
    "double_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class = SpatialDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class.filename= i_file.value\n",
    "i_class.acquisition = i_acquisition.value\n",
    "i_class.name_pattern = i_name_pattern.value\n",
    "i_class.expname = i_expname.value\n",
    "i_class.data_reading()\n",
    "i_class.processingdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'SILAC_1': {'changes in Shape after filtering': {'Shape before categorical filtering': (10166,\n",
    "    90),\n",
    "   'Shape after categorical filtering': (10166, 90),\n",
    "   'Shape after Ratio H/L count (>= 3)/var (count>=2, var<30) filtering': (165237,\n",
    "    3),\n",
    "   'Shape after filtering for complete profiles': (135765, 3)},\n",
    "  'Analysis parameters': {'acquisition': 'SILAC',\n",
    "   'filename': '6_deep_maps.txt'}},\n",
    " 'LFQ_1': {'changes in Shape after filtering': {'Shape before categorical filtering': (7612,\n",
    "    60),\n",
    "   'Shape after categorical filtering': (7612, 60),\n",
    "   'Shape after MS/MS value filtering': (25651, 10),\n",
    "   'Shape after consecutive value filtering': (25651, 10)},\n",
    "  'Analysis parameters': {'acquisition': 'LFQ',\n",
    "   'filename': 'LFQ_proteinGroups.txt'}},\n",
    " 'LFQ_COVID': {'changes in Shape after filtering': {'Shape before categorical filtering': (10479,\n",
    "    48),\n",
    "   'Shape after categorical filtering': (10479, 48),\n",
    "   'Shape after MS/MS value filtering': (43078, 8),\n",
    "   'Shape after consecutive value filtering': (43078, 8)},\n",
    "  'Analysis parameters': {'acquisition': 'LFQ',\n",
    "   'filename': 'proteinGroupsCOVID.txt'}},\n",
    " 'LFQ_3': {'changes in Shape after filtering': {'Shape before categorical filtering': (10387,\n",
    "    42),\n",
    "   'Shape after categorical filtering': (10387, 42),\n",
    "   'Shape after MS/MS value filtering': (19047, 14),\n",
    "   'Shape after consecutive value filtering': (19047, 14)},\n",
    "  'Analysis parameters': {'acquisition': 'LFQ',\n",
    "   'filename': 'proteinGroups_LFQ_Deep_3_Maps.txt'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictio_all[i_expname.value]=dictio\n",
    "\n",
    "analysed_dataset = {\n",
    "    FILENAME_FOR_COMPARISON: {\n",
    "        data: processed dataframe reduced to available complexes,\n",
    "        analysis_summary: {\n",
    "            pgs_before: n,\n",
    "            pgs_categorical: n,\n",
    "            ...\n",
    "            },\n",
    "        analysis_parameters: {\n",
    "            acquisition:\n",
    "            filename:\n",
    "            msms_counts:\n",
    "            ...\n",
    "            },\n",
    "        spread_table: output_table\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#df_index = i_class.df_original.set_index([col for col in i_class.df_original.columns if any([re.match(s, col) for s in sets_LFQ]) == False])\n",
    "\n",
    "#df_index\n",
    "#pn.Row(i_file, read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class.shape_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def indexingdf_silac(df_filt, regex):\n",
    "            \"\"\" A multiindex will be generated, characterized by Map, Fraction and Type as level labels,\n",
    "            allowing the stacking and unstacking of the dataframe;\n",
    "\n",
    "            Args:\n",
    "                df_filt: dataframe, that was filtered for matches to the reverse database, matches only identified by\n",
    "                site, and potential contaminants.\n",
    "\n",
    "            Returns:\n",
    "                df_index: multiindex dataframe, which contains 3 level labels: Map (e.g. MAP1, MAP2, ...)\n",
    "                Fraction (03K, 06K, 12K, 24K, 80K), Type (Ratio H/L count,Ratio H/L variability [%], Ratio H/L),\n",
    "                rest of the information is stored in the index (Protein IDs, Majority protein IDs,\n",
    "                Protein names, Gene names, id)\n",
    "            \"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringency_silac(df_index):\n",
    "    \"\"\"The multiindex dataframe is subjected to stringency filtering. Only Proteins with complete profiles are\n",
    "    considered (a set of f.e. 5 SILAC ratios in case you have 5 fractions / any proteins with missing values\n",
    "    were rejected). Proteins were retained with 3 or more quantifications in each subfraction (=count). Furthermore,\n",
    "    proteins with only 2 quantification events in one or more subfraction were retained, if their ratio\n",
    "    variability for ratios obtained with 2 quantification events was below 30% (=var).\n",
    "    SILAC ratios were linearly normalized by division through the fraction median. Subsequently normalization\n",
    "    to SILAC loading was performed.\n",
    "\n",
    "    Args:\n",
    "        df_index: multiindex dataframe, which contains 3 level labels: MAP, Fraction, Type\n",
    "\n",
    "    Returns:\n",
    "        df_stringency_mapfracstacked: dataframe, in which \"MAP\" and \"Fraction\" are stacked;\n",
    "        the columns \"Ratio H/L count\", \"Ratio H/L variability [%]\", and \"Ratio H/L\" stored as single level indices\n",
    "    \"\"\"\n",
    "\n",
    "    # Fraction and Map will be stacked\n",
    "    df_stack = df_index.stack([\"Fraction\", 'Map'])\n",
    "\n",
    "    len_fractions = len(df_stack.index.get_level_values(\"Fraction\").unique())\n",
    "\n",
    "    # filtering for sufficient number of quantifications (count in 'Ratio H/L count'), taken\n",
    "    # variability (var in Ratio H/L variability [%]) into account\n",
    "    # zip: allows direct comparison of count and var\n",
    "    # only if the filtering parameters are fulfilled the data will be introduced into df_countvarfiltered_stacked\n",
    "    df_countvarfiltered_stacked = df_stack.loc[[count >= 3 or (count >= 2 and var < 30) for var, count in\n",
    "                                                zip(df_stack[\"Ratio H/L variability [%]\"],\n",
    "                                                    df_stack['Ratio H/L count'])]]\n",
    "\n",
    "    # \"Ratio H/L\":normalization to SILAC loading, each individual experiment (FractionXMap) will be divided by its median\n",
    "    # np.median([...]): only entries, that are not NANs are considered\n",
    "    df_normsilac_stacked = df_countvarfiltered_stacked[\"Ratio H/L\"].unstack([\"Fraction\", \"Map\"]).apply(\n",
    "        lambda x: x / np.median([el for el in x if not np.isnan(el)]), axis=0).stack([\"Map\", \"Fraction\"])\n",
    "\n",
    "    df_stringency_mapfracstacked = df_countvarfiltered_stacked[[\"Ratio H/L count\",\n",
    "                                                            \"Ratio H/L variability [%]\"]].join(\n",
    "        pd.DataFrame(df_normsilac_stacked, columns=[\"Ratio H/L\"]))\n",
    "\n",
    "    # dataframe is grouped (Map, id), that allows the filtering for complete profiles\n",
    "    df_stringency_mapfracstacked = df_stringency_mapfracstacked.groupby([\"Map\", \"id\"]).filter(\n",
    "        lambda x: len(x) >= len_fractions)\n",
    "\n",
    "    # Ratio H/L is converted into Ratio L/H\n",
    "    df_stringency_mapfracstacked[\"Ratio H/L\"] = df_stringency_mapfracstacked[\"Ratio H/L\"].transform(lambda x: 1 / x)\n",
    "\n",
    "\n",
    "    return df_stringency_mapfracstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stringency_mapfracstacked = stringency_silac(dfi_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stringency_mapfracstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringency_lfq(df_index, selff):\n",
    "    \"\"\"The multiindex dataframe is subjected to stringency filtering. Only Proteins which were identified with\n",
    "    at least [4] consecutive data points regarding the \"LFQ intensity\", and if summed MS/MS counts >= n(fractions)*[2]\n",
    "    (LFQ5: min 10 and LFQ6: min 12, respectively; coverage filtering) were included.\n",
    "\n",
    "    Args:\n",
    "        df_index: multiindex dataframe, which contains 3 level labels: MAP, Fraction, Typ\n",
    "\n",
    "    Returns:\n",
    "        df_stringency_mapfracstacked: dataframe, in which \"Map\" and \"Fraction\" is stacked;\n",
    "        \"LFQ intensity\" and \"MS/MS count\" define a single-level column index\n",
    "        \"\"\"\n",
    "\n",
    "    # retrieve number of fractions that are present in the dataset\n",
    "    df_fractionnumber_stacked = df_index.copy().stack(\"Fraction\")\n",
    "    number_fractions = len(df_fractionnumber_stacked.index.get_level_values(\"Fraction\").unique())\n",
    "\n",
    "    df_index = df_index.stack(\"Map\")\n",
    "\n",
    "    # level 0 = Fraction, level 1 = Type is converted into level 0 = Type, level 1 = Fraction\n",
    "    #df_index.columns = df_index.columns.swaplevel(0, 1)\n",
    "\n",
    "    # sorting the level 0, in order to have LFQ intensity -\tMS/MS count instead of continuous alternation\n",
    "    df_index.sort_index(axis=1, level=0, inplace=True)\n",
    "\n",
    "    # \"MS/MS count\"-column: take the sum over the fractions;\n",
    "    # if the sum is larger than n[fraction]*2, it will be stored in the new dataframe\n",
    "    df_mscount_mapstacked = df_index.loc[df_index[('MS/MS count')].apply(np.sum, axis=1) >= (\n",
    "            number_fractions * selff.summed_MSMS_counts)]\n",
    "\n",
    "    df_stringency_mapfracstacked = df_mscount_mapstacked.copy()\n",
    "\n",
    "    # series no dataframe is generated; if there are at least i.e. 4 consecutive non-NANs, data will be retained\n",
    "    df_stringency_mapfracstacked = df_stringency_mapfracstacked.loc[\n",
    "        df_stringency_mapfracstacked[(\"LFQ intensity\")].apply(lambda x: any(\n",
    "            np.invert(np.isnan(x)).rolling(window=selff.consecutive_LFQ_I).sum() >=\n",
    "            selff.consecutive_LFQ_I), axis=1)]\n",
    "\n",
    "    df_stringency_mapfracstacked = df_stringency_mapfracstacked.copy().stack(\"Fraction\")\n",
    "\n",
    "    return df_stringency_mapfracstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stringency_mapfracstacked = stringency_lfq(dfi_1, i_class)\n",
    "df_stringency_mapfracstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
